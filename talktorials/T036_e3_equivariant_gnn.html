<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="T036 · An introduction to E(3)-invariant graph neural networks" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://projects.volkamerlab.org/teachopencadd/talktorials/T036_e3_equivariant_gnn.html" />
<meta property="og:site_name" content="TeachOpenCADD" />
<meta property="og:description" content="Note: This talktorial is a part of TeachOpenCADD, a platform that aims to teach domain-specific skills and to provide pipeline templates as starting points for research projects. Authors: Joschka Groß, 2022, Chair for Modelling and Simulation, NextAID project, Saarland University. Aim of this tal..." />
<meta property="og:image" content="https://raw.githubusercontent.com/volkamerlab/teachopencadd/master/docs/_static/images/TeachOpenCADD_topics.png" />
<meta property="og:image:alt" content="TeachOpenCADD" />
<meta name="description" content="Note: This talktorial is a part of TeachOpenCADD, a platform that aims to teach domain-specific skills and to provide pipeline templates as starting points for research projects. Authors: Joschka Groß, 2022, Chair for Modelling and Simulation, NextAID project, Saarland University. Aim of this tal..." />

  <meta name="viewport" content="width=device-width,initial-scale=1">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="lang:clipboard.copy" content="Copy to clipboard">
  <meta name="lang:clipboard.copied" content="Copied to clipboard">
  <meta name="lang:search.language" content="en">
  <meta name="lang:search.pipeline.stopwords" content="True">
  <meta name="lang:search.pipeline.trimmer" content="True">
  <meta name="lang:search.result.none" content="No matching documents">
  <meta name="lang:search.result.one" content="1 matching document">
  <meta name="lang:search.result.other" content="# matching documents">
  <meta name="lang:search.tokenizer" content="[\s\-]+">

  
    <link href="https://fonts.gstatic.com/" rel="preconnect" crossorigin>
    <link href="https://fonts.googleapis.com/css?family=Roboto+Mono:400,500,700|Roboto:300,400,400i,700&display=fallback" rel="stylesheet">

    <style>
      body,
      input {
        font-family: "Roboto", "Helvetica Neue", Helvetica, Arial, sans-serif
      }

      code,
      kbd,
      pre {
        font-family: "Roboto Mono", "Courier New", Courier, monospace
      }
    </style>
  

  <link rel="stylesheet" href="../_static/stylesheets/application.css"/>
  <link rel="stylesheet" href="../_static/stylesheets/application-palette.css"/>
  <link rel="stylesheet" href="../_static/stylesheets/application-fixes.css"/>
  
  <link rel="stylesheet" href="../_static/fonts/material-icons.css"/>
  
  <meta name="theme-color" content="#2196f3">
  <script src="../_static/javascripts/modernizr.js"></script>
  
    <script async src="../_static/cookieconsent.min.js"></script>
    <script>
        window.addEventListener("load", function(){
        window.cookieconsent.initialise({
            "palette": {
            "popup": {
                "background": "#f0f0f0",
                "text": "#999"
            },
            "button": {
                "text": "#fff",
                "background": "#009688"
            }
            },
            "theme": "classic"
        })});
    </script>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-Q6ZE82CNZB"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-Q6ZE82CNZB');
    </script>
  
    <link rel="apple-touch-icon" href="../_static/images/apple-icon-152x152.png"/>
  
  
    <title>T036 · An introduction to E(3)-invariant graph neural networks &#8212; TeachOpenCADD 0 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=80d5e7a1" />
    <link rel="stylesheet" type="text/css" href="../_static/material.css?v=79c92029" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=61a4c737" />
    <link rel="stylesheet" type="text/css" href="../_static/nbsphinx-code-cells.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=897d968c" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js?v=e43216b9"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=4825356b"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="T037 · Uncertainty estimation" href="T037_uncertainty_estimation.html" />
    <link rel="prev" title="T035 · GNN-based molecular property prediction" href="T035_graph_neural_networks.html" />
  
    <link rel="apple-touch-icon" href="../_static/images/apple-icon-152x152.png"/>
  
   

  </head>
  <body dir=ltr
        data-md-color-primary=teal data-md-color-accent=cyan>
  
  <svg class="md-svg">
    <defs data-children-count="0">
      
      <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="__github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg>
      
    </defs>
  </svg>
  
  <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer">
  <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search">
  <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
  <a href="#talktorials/T036_e3_equivariant_gnn" tabindex="1" class="md-skip"> Skip to content </a>
  <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex navheader">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="../index.html" title="TeachOpenCADD 0 documentation"
           class="md-header-nav__button md-logo">
          
            <i class="md-icon">school</i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          <span class="md-header-nav__topic">TeachOpenCADD</span>
          <span class="md-header-nav__topic"> T036 · An introduction to E(3)-invariant graph neural networks </span>
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
        
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" action="../search.html" method="get" name="search">
      <input type="text" class="md-search__input" name="q" placeholder="Search"
             autocapitalize="off" autocomplete="off" spellcheck="false"
             data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>

      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            <a href="https://github.com/volkamerlab/teachopencadd/" title="Go to repository" class="md-source" data-md-source="github">

    <div class="md-source__icon">
      <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 24 24" width="28" height="28">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    TeachOpenCADD
  </div>
</a>
          </div>
        </div>
      
      
    </div>
  </nav>
</header>

  
  <div class="md-container">
    
    
    
  <nav class="md-tabs" data-md-component="tabs">
    <div class="md-tabs__inner md-grid">
      <ul class="md-tabs__list">
            
            <li class="md-tabs__item"><a href="../talktorials.html" class="md-tabs__link">Our talktorials</a></li>
            
            <li class="md-tabs__item"><a href="../installing.html" class="md-tabs__link">Run locally</a></li>
            
            <li class="md-tabs__item"><a href="../contribute.html" class="md-tabs__link">Development</a></li>
            
            <li class="md-tabs__item"><a href="../contact.html" class="md-tabs__link">Contact</a></li>
            
            <li class="md-tabs__item"><a href="../citation.html" class="md-tabs__link">Citation</a></li>
          <li class="md-tabs__item"><a href="../all_talktorials.html" class="md-tabs__link">Complete list of talktorials</a></li>
      </ul>
    </div>
  </nav>
    <main class="md-main">
      <div class="md-main__inner md-grid" data-md-component="container">
        
          <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="../index.html" title="TeachOpenCADD 0 documentation" class="md-nav__button md-logo">
      
        <i class="md-icon">school</i>
      
    </a>
    <a href="../index.html"
       title="TeachOpenCADD 0 documentation">TeachOpenCADD</a>
  </label>
    <div class="md-nav__source">
      <a href="https://github.com/volkamerlab/teachopencadd/" title="Go to repository" class="md-source" data-md-source="github">

    <div class="md-source__icon">
      <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 24 24" width="28" height="28">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    TeachOpenCADD
  </div>
</a>
    </div>
  
  

  
  <ul class="md-nav__list">
    <li class="md-nav__item">
    
      <span class="md-nav__link caption"><span class="caption-text">Our talktorials</span></span>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../all_talktorials.html" class="md-nav__link">Complete list of talktorials</a>
      <ul class="md-nav__list"> 
    <li class="md-nav__item">
    
    
      <a href="T001_query_chembl.html" class="md-nav__link">T001 · Compound data acquisition (ChEMBL)</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="T002_compound_adme.html" class="md-nav__link">T002 · Molecular filtering: ADME and lead-likeness criteria</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="T003_compound_unwanted_substructures.html" class="md-nav__link">T003 · Molecular filtering: unwanted substructures</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="T004_compound_similarity.html" class="md-nav__link">T004 · Ligand-based screening: compound similarity</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="T005_compound_clustering.html" class="md-nav__link">T005 · Compound clustering</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="T006_compound_maximum_common_substructures.html" class="md-nav__link">T006 · Maximum common substructure</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="T007_compound_activity_machine_learning.html" class="md-nav__link">T007 · Ligand-based screening: machine learning</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="T008_query_pdb.html" class="md-nav__link">T008 · Protein data acquisition: Protein Data Bank (PDB)</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="T009_compound_ensemble_pharmacophores.html" class="md-nav__link">T009 · Ligand-based pharmacophores</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="T010_binding_site_comparison.html" class="md-nav__link">T010 · Binding site similarity and off-target prediction</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="T011_query_online_api_webservices.html" class="md-nav__link">T011 · Querying online API webservices</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="T012_query_klifs.html" class="md-nav__link">T012 · Data acquisition from KLIFS</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="T013_query_pubchem.html" class="md-nav__link">T013 · Data acquisition from PubChem</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="T014_binding_site_detection.html" class="md-nav__link">T014 · Binding site detection</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="T015_protein_ligand_docking.html" class="md-nav__link">T015 · Protein ligand docking</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="T016_protein_ligand_interactions.html" class="md-nav__link">T016 · Protein-ligand interactions</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="T017_advanced_nglview_usage.html" class="md-nav__link">T017 · Advanced NGLview usage</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="T018_automated_cadd_pipeline.html" class="md-nav__link">T018 · Automated pipeline for lead optimization</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="T019_md_simulation.html" class="md-nav__link">T019 · Molecular dynamics simulation</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="T020_md_analysis.html" class="md-nav__link">T020 · Analyzing molecular dynamics simulations</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="T021_one_hot_encoding.html" class="md-nav__link">T021 · One-Hot Encoding</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="T022_ligand_based_screening_neural_network.html" class="md-nav__link">T022 · Ligand-based screening: neural networks</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="T023_what_is_a_kinase.html" class="md-nav__link">T023 · What is a kinase?</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="T024_kinase_similarity_sequence.html" class="md-nav__link">T024 · Kinase similarity: Sequence</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="T025_kinase_similarity_kissim.html" class="md-nav__link">T025 · Kinase similarity: Kinase pocket (KiSSim fingerprint)</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="T026_kinase_similarity_ifp.html" class="md-nav__link">T026 · Kinase similarity: Interaction fingerprints</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="T027_kinase_similarity_ligand_profile.html" class="md-nav__link">T027 · Kinase similarity: Ligand profile</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="T028_kinase_similarity_compare_perspectives.html" class="md-nav__link">T028 · Kinase similarity: Compare different perspectives</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="T033_molecular_representations.html" class="md-nav__link">T033 · Molecular representations</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="T034_recurrent_neural_networks.html" class="md-nav__link">T034 · RNN-based molecular property prediction</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="T035_graph_neural_networks.html" class="md-nav__link">T035 · GNN-based molecular property prediction</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    <label class="md-nav__link md-nav__link--active" for="__toc"> T036 · An introduction to E(3)-invariant graph neural networks </label>
    
      <a href="#" class="md-nav__link md-nav__link--active">T036 · An introduction to E(3)-invariant graph neural networks</a>
      
        
<nav class="md-nav md-nav--secondary">
    <label class="md-nav__title" for="__toc">Contents</label>
  <ul class="md-nav__list" data-md-scrollfix="">
        <li class="md-nav__item"><a href="#talktorials-t036-e3-equivariant-gnn--page-root" class="md-nav__link">T036 · An introduction to E(3)-invariant graph neural networks</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#Aim-of-this-talktorial" class="md-nav__link">Aim of this talktorial</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#Contents-in-Theory" class="md-nav__link">Contents in <em>Theory</em></a>
        </li>
        <li class="md-nav__item"><a href="#Contents-in-Practical" class="md-nav__link">Contents in <em>Practical</em></a>
        </li>
        <li class="md-nav__item"><a href="#References" class="md-nav__link">References</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#Theoretical" class="md-nav__link">Theoretical</a>
        </li>
        <li class="md-nav__item"><a href="#Practical" class="md-nav__link">Practical</a>
        </li></ul>
            </nav>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#Theory" class="md-nav__link">Theory</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#Why-3D-coordinates?" class="md-nav__link">Why 3D coordinates?</a>
        </li>
        <li class="md-nav__item"><a href="#Molecules-as-point-clouds:-mathematical-background" class="md-nav__link">Molecules as point clouds: mathematical background</a>
        </li>
        <li class="md-nav__item"><a href="#Equivariance-and-Invariance-in-Euclidean-space-and-why-we-care" class="md-nav__link">Equivariance and Invariance in Euclidean space and why we care</a>
        </li>
        <li class="md-nav__item"><a href="#How-to-construct-\text{E}(n)-invariant-and-equivariant-models" class="md-nav__link">How to construct <span class="math notranslate nohighlight">\(\text{E}(n)\)</span>-invariant and equivariant models</a>
        </li>
        <li class="md-nav__item"><a href="#The-QM9-dataset" class="md-nav__link">The QM9 dataset</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#id1" class="md-nav__link">Practical</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#Visualization-of-point-clouds" class="md-nav__link">Visualization of point clouds</a>
        </li>
        <li class="md-nav__item"><a href="#Set-up-and-inspect-the-QM9-dataset" class="md-nav__link">Set up and inspect the QM9 dataset</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#Preprocessing" class="md-nav__link">Preprocessing</a>
        </li>
        <li class="md-nav__item"><a href="#Atomic-number-distribution-and-point-cloud-size" class="md-nav__link">Atomic number distribution and point cloud size</a>
        </li>
        <li class="md-nav__item"><a href="#Data-split,-distribution-of-regression-target-electronic-spatial-extent" class="md-nav__link">Data split, distribution of regression target electronic spatial extent</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#Model-implementation" class="md-nav__link">Model implementation</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#Plain-%22naive-Euclidean%22-GNN" class="md-nav__link">Plain “naive Euclidean” GNN</a>
        </li>
        <li class="md-nav__item"><a href="#Demo:-Plain-GNNs-are-not-\text{E(3)}-invariant" class="md-nav__link">Demo: Plain GNNs are not <span class="math notranslate nohighlight">\(\text{E(3)}\)</span>-invariant</a>
        </li>
        <li class="md-nav__item"><a href="#EGNN-model" class="md-nav__link">EGNN model</a>
        </li>
        <li class="md-nav__item"><a href="#Demo:-Our-EGNN-is-E(3)-invariant" class="md-nav__link">Demo: Our EGNN is <span class="math notranslate nohighlight">\(E(3)\)</span>-invariant</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#Training-and-evaluation" class="md-nav__link">Training and evaluation</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#Training-the-EGNN" class="md-nav__link">Training the EGNN</a>
        </li>
        <li class="md-nav__item"><a href="#Training-the-plain-GNN" class="md-nav__link">Training the plain GNN</a>
        </li>
        <li class="md-nav__item"><a href="#Comparative-evaluation" class="md-nav__link">Comparative evaluation</a>
        </li></ul>
            </nav>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#Discussion" class="md-nav__link">Discussion</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#Summary" class="md-nav__link">Summary</a>
        </li>
        <li class="md-nav__item"><a href="#Caveats-of-our-approach" class="md-nav__link">Caveats of our approach</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#Quiz" class="md-nav__link">Quiz</a>
        </li></ul>
            </nav>
        </li>
    
<li class="md-nav__item"><a class="md-nav__extra_link" href="../_sources/talktorials/T036_e3_equivariant_gnn.nblink.txt">Show Source</a> </li>

  </ul>
</nav>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="T037_uncertainty_estimation.html" class="md-nav__link">T037 · Uncertainty estimation</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="T038_protein_ligand_interaction_prediction.html" class="md-nav__link">T038 · Protein Ligand Interaction Prediction</a>
      
    
    </li></ul>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../talktorials.html" class="md-nav__link">Talktorials by collection</a>
      
    
    </li>
    <li class="md-nav__item">
    
      <span class="md-nav__link caption"><span class="caption-text">Run locally</span></span>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../installing.html" class="md-nav__link">Installing</a>
      
    
    </li>
    <li class="md-nav__item">
    
      <span class="md-nav__link caption"><span class="caption-text">Development</span></span>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../contribute.html" class="md-nav__link">For contributors</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../api.html" class="md-nav__link">API Documentation</a>
      
    
    </li>
    <li class="md-nav__item">
    
      <span class="md-nav__link caption"><span class="caption-text">About TeachOpenCADD</span></span>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../contact.html" class="md-nav__link">Contact</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../acknowledgments.html" class="md-nav__link">Acknowledgments</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../citation.html" class="md-nav__link">Citation</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../license.html" class="md-nav__link">License</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../funding.html" class="md-nav__link">Funding</a>
      
    
    </li>
    <li class="md-nav__item">
    
      <span class="md-nav__link caption"><span class="caption-text">External resources</span></span>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../external_dependencies.html" class="md-nav__link">Packages and webservers used in TeachOpenCADD</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../external_tutorials_collections.html" class="md-nav__link">External tutorials and collections</a>
      
    
    </li>
  </ul>
  

</nav>
              </div>
            </div>
          </div>
          <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                
<nav class="md-nav md-nav--secondary">
    <label class="md-nav__title" for="__toc">Contents</label>
  <ul class="md-nav__list" data-md-scrollfix="">
        <li class="md-nav__item"><a href="#talktorials-t036-e3-equivariant-gnn--page-root" class="md-nav__link">T036 · An introduction to E(3)-invariant graph neural networks</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#Aim-of-this-talktorial" class="md-nav__link">Aim of this talktorial</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#Contents-in-Theory" class="md-nav__link">Contents in <em>Theory</em></a>
        </li>
        <li class="md-nav__item"><a href="#Contents-in-Practical" class="md-nav__link">Contents in <em>Practical</em></a>
        </li>
        <li class="md-nav__item"><a href="#References" class="md-nav__link">References</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#Theoretical" class="md-nav__link">Theoretical</a>
        </li>
        <li class="md-nav__item"><a href="#Practical" class="md-nav__link">Practical</a>
        </li></ul>
            </nav>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#Theory" class="md-nav__link">Theory</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#Why-3D-coordinates?" class="md-nav__link">Why 3D coordinates?</a>
        </li>
        <li class="md-nav__item"><a href="#Molecules-as-point-clouds:-mathematical-background" class="md-nav__link">Molecules as point clouds: mathematical background</a>
        </li>
        <li class="md-nav__item"><a href="#Equivariance-and-Invariance-in-Euclidean-space-and-why-we-care" class="md-nav__link">Equivariance and Invariance in Euclidean space and why we care</a>
        </li>
        <li class="md-nav__item"><a href="#How-to-construct-\text{E}(n)-invariant-and-equivariant-models" class="md-nav__link">How to construct <span class="math notranslate nohighlight">\(\text{E}(n)\)</span>-invariant and equivariant models</a>
        </li>
        <li class="md-nav__item"><a href="#The-QM9-dataset" class="md-nav__link">The QM9 dataset</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#id1" class="md-nav__link">Practical</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#Visualization-of-point-clouds" class="md-nav__link">Visualization of point clouds</a>
        </li>
        <li class="md-nav__item"><a href="#Set-up-and-inspect-the-QM9-dataset" class="md-nav__link">Set up and inspect the QM9 dataset</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#Preprocessing" class="md-nav__link">Preprocessing</a>
        </li>
        <li class="md-nav__item"><a href="#Atomic-number-distribution-and-point-cloud-size" class="md-nav__link">Atomic number distribution and point cloud size</a>
        </li>
        <li class="md-nav__item"><a href="#Data-split,-distribution-of-regression-target-electronic-spatial-extent" class="md-nav__link">Data split, distribution of regression target electronic spatial extent</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#Model-implementation" class="md-nav__link">Model implementation</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#Plain-%22naive-Euclidean%22-GNN" class="md-nav__link">Plain “naive Euclidean” GNN</a>
        </li>
        <li class="md-nav__item"><a href="#Demo:-Plain-GNNs-are-not-\text{E(3)}-invariant" class="md-nav__link">Demo: Plain GNNs are not <span class="math notranslate nohighlight">\(\text{E(3)}\)</span>-invariant</a>
        </li>
        <li class="md-nav__item"><a href="#EGNN-model" class="md-nav__link">EGNN model</a>
        </li>
        <li class="md-nav__item"><a href="#Demo:-Our-EGNN-is-E(3)-invariant" class="md-nav__link">Demo: Our EGNN is <span class="math notranslate nohighlight">\(E(3)\)</span>-invariant</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#Training-and-evaluation" class="md-nav__link">Training and evaluation</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#Training-the-EGNN" class="md-nav__link">Training the EGNN</a>
        </li>
        <li class="md-nav__item"><a href="#Training-the-plain-GNN" class="md-nav__link">Training the plain GNN</a>
        </li>
        <li class="md-nav__item"><a href="#Comparative-evaluation" class="md-nav__link">Comparative evaluation</a>
        </li></ul>
            </nav>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#Discussion" class="md-nav__link">Discussion</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#Summary" class="md-nav__link">Summary</a>
        </li>
        <li class="md-nav__item"><a href="#Caveats-of-our-approach" class="md-nav__link">Caveats of our approach</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#Quiz" class="md-nav__link">Quiz</a>
        </li></ul>
            </nav>
        </li>
    
<li class="md-nav__item"><a class="md-nav__extra_link" href="../_sources/talktorials/T036_e3_equivariant_gnn.nblink.txt">Show Source</a> </li>

<li id="searchbox" class="md-nav__item"></li>

  </ul>
</nav>
              </div>
            </div>
          </div>
        
        <div class="md-content">
          <article class="md-content__inner md-typeset" role="main">
            
  <section id="T036-·-An-introduction-to-E(3)-invariant-graph-neural-networks">
<h1 id="talktorials-t036-e3-equivariant-gnn--page-root">T036 · An introduction to E(3)-invariant graph neural networks<a class="headerlink" href="#talktorials-t036-e3-equivariant-gnn--page-root" title="Permalink to this heading">¶</a></h1>
<p><strong>Note:</strong> This talktorial is a part of TeachOpenCADD, a platform that aims to teach domain-specific skills and to provide pipeline templates as starting points for research projects.</p>
<p>Authors:</p>
<ul class="simple">
<li><p>Joschka Groß, 2022, <a class="reference external" href="https://mosi.uni-saarland.de/">Chair for Modelling and Simulation</a>, <a class="reference external" href="https://nextaid.cs.uni-saarland.de/">NextAID</a> project, Saarland University</p></li>
</ul>
<section id="Aim-of-this-talktorial">
<h2 id="Aim-of-this-talktorial">Aim of this talktorial<a class="headerlink" href="#Aim-of-this-talktorial" title="Permalink to this heading">¶</a></h2>
<p>This talktorial is supposed to serve as an introduction to machine learning on point cloud representations of molecules with 3D conformer information, i.e., molecular graphs that are embedded into Euclidean space (see <strong>Talktorial 033</strong>). You will learn why Euclidean equivariance and invariance are important properties of neural networks (NNs) that take point clouds as input and learn how to implement and train such NNs. In addition to discussing them in theory, this notebook also aims to
demonstrate the shortcomings of plain graph neural networks (GNNs) when working with point clouds practically.</p>
<section id="Contents-in-Theory">
<h3 id="Contents-in-Theory">Contents in <em>Theory</em><a class="headerlink" href="#Contents-in-Theory" title="Permalink to this heading">¶</a></h3>
<ul class="simple">
<li><p>Why 3D coordinates?</p></li>
<li><p>Representing molecules as point clouds</p></li>
<li><p>Equivariance and Invariance in euclidean space and why we care</p></li>
<li><p>How to construct <span class="math notranslate nohighlight">\(\text{E}(n)\)</span>-invariant and equivariant models</p></li>
<li><p>The QM9 dataset</p></li>
</ul>
</section>
<section id="Contents-in-Practical">
<h3 id="Contents-in-Practical">Contents in <em>Practical</em><a class="headerlink" href="#Contents-in-Practical" title="Permalink to this heading">¶</a></h3>
<ul class="simple">
<li><p>Visualization of point clouds</p></li>
<li><p>Set up and inspect the QM9 dataset</p>
<ul>
<li><p>Preprocessing</p></li>
<li><p>Atomic number distribution and point cloud size</p></li>
<li><p>Data split, distribution of regression target electronic spatial extent</p></li>
</ul>
</li>
<li><p>Model implementation</p>
<ul>
<li><p>Plain “naive Euclidean” GNN</p></li>
<li><p>Demo: Plain GNNs are not E(3)-invariant</p></li>
<li><p>EGNN model</p></li>
<li><p>Demo: Our EGNN is E(3)-invariant</p></li>
</ul>
</li>
<li><p>Training and evaluation</p>
<ul>
<li><p>Setup</p></li>
<li><p>Training the EGNN</p></li>
<li><p>Training the plain GNN</p></li>
<li><p>Comparative evaluation</p></li>
</ul>
</li>
</ul>
</section>
<section id="References">
<h3 id="References">References<a class="headerlink" href="#References" title="Permalink to this heading">¶</a></h3>
<section id="Theoretical">
<h4 id="Theoretical">Theoretical<a class="headerlink" href="#Theoretical" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p><strong>Quantum chemistry structures and properties of 134k molecules (QM9)</strong>: <a class="reference external" href="https://www.nature.com/articles/sdata201422/?ref=https://githubhelp.com">Scientific data (2014)</a></p></li>
<li><p><strong>MoleculeNet: a benchmark for molecular machine learning</strong>: <a class="reference external" href="https://pubs.rsc.org/en/content/articlehtml/2018/sc/c7sc02664a">Chem. Sci., 2018, 9, 513-530</a></p></li>
<li><p><strong>E(n)-Equivariant Graph Neural Networks</strong>: <a class="reference external" href="https://proceedings.mlr.press/v139/satorras21a.html">International conference on machine learning (2021), 139, 99323-9332</a></p></li>
<li><p><strong>SE(3)-transformers: 3D roto-translation equivariant attention networks</strong>: <a class="reference external" href="https://proceedings.neurips.cc/paper/2020/file/15231a7ce4ba789d13b722cc5c955834-Paper.pdf">Advances in Neural Information Processing Systems (2021), 33, 1970-1981</a></p></li>
<li><p><strong>TorchMD-NET: Equivariant Transformers for Neural Network based Molecular Potentials</strong>: <a class="reference external" href="https://arxiv.org/abs/2202.02541">arXiv preprint (2022)</a></p></li>
<li><p><strong>DiffDock</strong>: <a class="reference external" href="https://arxiv.org/abs/2210.01776">arXiv preprint (2022)</a></p></li>
</ul>
</section>
<section id="Practical">
<h4 id="Practical">Practical<a class="headerlink" href="#Practical" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p><a class="reference external" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/datasets.html#torch_geometric.datasets.QM9">Pytorch Geometric QM9 version</a></p></li>
</ul>
</section>
</section>
</section>
<section id="Theory">
<h2 id="Theory">Theory<a class="headerlink" href="#Theory" title="Permalink to this heading">¶</a></h2>
<section id="Why-3D-coordinates?">
<h3 id="Why-3D-coordinates?">Why 3D coordinates?<a class="headerlink" href="#Why-3D-coordinates?" title="Permalink to this heading">¶</a></h3>
<ul class="simple">
<li><p>Some properties are more easily derived when 3D coordinates are known.</p></li>
<li><p>Sometimes the task is to predict properties that are directly linked to Euclidean space, e.g. future atom positions or forces that apply to atoms.</p></li>
<li><p>Compared to molecular graph representations, we in principle only gain information. Covalent bonds can still be inferred from atom types and positions because they can be attributed to overlapping atomic orbitals. Note that one could still include structural information s.t. the model does not have to learn this information itself</p></li>
</ul>
<p>An example CADD application that may require the use of 3D coordinates is protein-ligand docking (see <strong>Talktorial 015</strong>). <a class="reference external" href="https://arxiv.org/abs/2210.01776">Recent work from 2022</a> uses E(3) equivariant graph neural networks as the backbone for a generative model that learns to predict potential ligand docking positions (3D coordinates for the atoms of a given ligand) when additionally given protein structures with 3D information as input.</p>
</section>
<section id="Molecules-as-point-clouds:-mathematical-background">
<h3 id="Molecules-as-point-clouds:-mathematical-background">Molecules as point clouds: mathematical background<a class="headerlink" href="#Molecules-as-point-clouds:-mathematical-background" title="Permalink to this heading">¶</a></h3>
<p>In this talktorial we will focus on atoms and their 3D positions and ignore structural (bond) information. Our mathematical representations of a molecule is thus a point cloud (also see <strong>Talktorial T033</strong>), i.e., a tuple <span class="math notranslate nohighlight">\((X, Z)\)</span> where <span class="math notranslate nohighlight">\(Z \in \mathbb{R}^{m \times d}\)</span> is a matrix of <span class="math notranslate nohighlight">\(m\)</span> atoms represented by <span class="math notranslate nohighlight">\(d\)</span> features each and <span class="math notranslate nohighlight">\(X \in \mathbb{R}^{m \times 3}\)</span> captures the atom 3D coordinates. We will assume that the coordinates correspond to a specific molecular
conformation (see <strong>Talktorial T033</strong>) of the molecule.</p>
</section>
<section id="Equivariance-and-Invariance-in-Euclidean-space-and-why-we-care">
<h3 id="Equivariance-and-Invariance-in-Euclidean-space-and-why-we-care">Equivariance and Invariance in Euclidean space and why we care<a class="headerlink" href="#Equivariance-and-Invariance-in-Euclidean-space-and-why-we-care" title="Permalink to this heading">¶</a></h3>
<p>When representing molecules as graphs equi- and/or invariance w.r.t. to node permutations are desirable model properties (<strong>Talktorial T033/T035</strong>). When working with point clouds, i.e., when atoms/nodes are embedded into Euclidean space, we should also be concerned about Euclidean symmetry groups. These are groups of transformations <span class="math notranslate nohighlight">\(g: \mathbb{R}^n \to \mathbb{R}^n\)</span> that preserve distance, i.e., translations, rotations, reflections, or combinations thereof. For the Euclidean space
<span class="math notranslate nohighlight">\(\mathbb{R}^n\)</span> with <span class="math notranslate nohighlight">\(n\)</span> spatial dimensions, one typically distinguishes between</p>
<ul class="simple">
<li><p>the Euclidean group <span class="math notranslate nohighlight">\(\text{E}(n)\)</span>, which consists of <em>all</em> distance-preserving transformations, and</p></li>
<li><p>the special Euclidean group <span class="math notranslate nohighlight">\(\text{SE}(n)\)</span>, which consists only of translations and rotations.</p></li>
</ul>
<p>Say <span class="math notranslate nohighlight">\(\theta\)</span> is a model that learns atom embeddings <span class="math notranslate nohighlight">\(H = \theta(X, Z) \in \mathbb{R}^{m \times q}\)</span> where <span class="math notranslate nohighlight">\(q\)</span> is the number of embedding dimensions. We call <span class="math notranslate nohighlight">\(\theta\)</span> <span class="math notranslate nohighlight">\(\text{E}(n)\)</span>-<em>invariant</em>, if for all <span class="math notranslate nohighlight">\(g \in \text{E}(n)\)</span></p>
<div class="math notranslate nohighlight">
\[\theta(g(X), Z) = \theta(X, Z),\]</div>
<p>where <span class="math notranslate nohighlight">\(g\)</span> is applied row-wise to <span class="math notranslate nohighlight">\(X\)</span>. Put simply the output of <span class="math notranslate nohighlight">\(\theta\)</span> remains unaffected, no matter how we rotate, translate, or reflect the molecule.</p>
<p>If we consider a model that makes predictions about objects which are coupled to the Euclidean space <span class="math notranslate nohighlight">\(X' = \theta(X, Z) \in \mathbb{R}^{m \times n}\)</span> (e.g. future atom positions in a dynamical system), we can define <span class="math notranslate nohighlight">\(\text{E}(n)\)</span>-<em>equivariance</em> as</p>
<div class="math notranslate nohighlight">
\[\theta(g(X), Z) = g(\theta(X, Z)),\]</div>
<p>for all <span class="math notranslate nohighlight">\(g \in \text{E}(n)\)</span> applied in row-wise fashion. This is saying that the output of <span class="math notranslate nohighlight">\(\theta\)</span> is transformed in the same way as its input. Note that this definition can easily be extended to arbitrary Euclidean features (velocities, electromagnetic forces, …).</p>
<p>So, why do we care about these properties?</p>
<p>Let’s assume our goal was to train a model that predicts the docking position of a ligand when given a fixed protein structure, also with 3D coordinates. Would you trust a model that predicted different relative positions for the ligand atoms when the protein was simply rotated by 180 degrees? If your answer is no, then you should consider using a model that is at least <span class="math notranslate nohighlight">\(\text{SE}(3)\)</span>-equivariant. In addition to being a “natural” choice given such considerations, euclidean equivariance
empirically also increases the sample complexity (efficiency) of training and improves the model’s ability to generalize to unseen data.</p>
<p><strong>To sum up</strong> it may be helpful to address the problem from a slightly different point of view: Point clouds as representations for molecular conformations are <em>not unique</em>. In fact, for one molecular conformation, there are <em>infinitely many</em> valid point cloud representations. If <span class="math notranslate nohighlight">\((X, Z)\)</span> is such a representation then <span class="math notranslate nohighlight">\((g(X), Z)\)</span> with <span class="math notranslate nohighlight">\(g \in \text{E}(3)\)</span> is too and there are infinitely many such <span class="math notranslate nohighlight">\(g\)</span>. All <span class="math notranslate nohighlight">\(\text{E}(3)\)</span>-invariance and equivariance are thus saying, is
that our machine learning models <em>should not care</em> which of these representations we end up using.</p>
<p><img alt="Figure title" src="../_images/2d_rotation_equivariance.png"/></p>
<p><em>Figure 1:</em> An illustration of a 2D-rotationally equi- and invariant transformation <span class="math notranslate nohighlight">\(\phi\)</span>. Taken from <a class="reference external" href="https://proceedings.mlr.press/v139/satorras21a.html">the EGNN paper by Satoras et. al.</a></p>
</section>
<section id="How-to-construct-\text{E}(n)-invariant-and-equivariant-models">
<h3 id="How-to-construct-\text{E}(n)-invariant-and-equivariant-models">How to construct <span class="math notranslate nohighlight">\(\text{E}(n)\)</span>-invariant and equivariant models<a class="headerlink" href="#How-to-construct-\text{E}(n)-invariant-and-equivariant-models" title="Permalink to this heading">¶</a></h3>
<p>Constructing such models is simple if we focus on the fact that all <span class="math notranslate nohighlight">\(g \in \text{E}(n)\)</span> are <em>distance-preserving</em>. We will not give a <a class="reference external" href="https://proceedings.mlr.press/v139/satorras21a.html">fully-fledged proof</a>, but it should not come as a great surprise that a model which <em>only considers relative distances between atoms</em> for computing node (atom) embeddings is guaranteed to be <span class="math notranslate nohighlight">\(E(n)\)</span>-invariant. We can thus define a <em>message passing network</em> <span class="math notranslate nohighlight">\(\theta(Z, X)\)</span> with
<span class="math notranslate nohighlight">\(l=1,\ldots,L\)</span> layers where</p>
<div class="math notranslate nohighlight">
\[h_{i}^0 = \psi_0(Z_i)\]</div>
<div class="math notranslate nohighlight">
\[d_{ij} = ||X_i - X_j||^2\]</div>
<div class="math notranslate nohighlight">
\[m_{ij}^{l} = \phi_{l}(h_i^l, h_j^l, d_{ij})  \quad \quad \text{for}~l=0,\ldots,L-1\]</div>
<div class="math notranslate nohighlight">
\[h_{i}^{l+1} = \psi_l(h_{i}^l, \sum_{j \neq i} m_{ij}^l) \quad \quad \text{for}~l=0,\ldots,L-1\]</div>
<p>and <span class="math notranslate nohighlight">\(\psi_0\)</span> computes the initial node embeddings, the <span class="math notranslate nohighlight">\(\phi_l\)</span> MLPs <span class="math notranslate nohighlight">\(\text{}^1\)</span> construct messages and <span class="math notranslate nohighlight">\(\psi_l\)</span> MLPs take care of combining previous embeddings and aggregated messages into new embeddings. The final node embeddings <span class="math notranslate nohighlight">\(H = (h_1^L \ldots h_n^L)^t\)</span> computed by this scheme are <span class="math notranslate nohighlight">\(E(n)\)</span>-invariant.</p>
<p>In the practical part, we will only predict properties that are not directly linked to the Euclidean space, so this kind of network suffices for our purposes. If your goal is to predict e.g. atom positions, you will need to define additional, slightly more sophisticated transformations to ensure that they are <span class="math notranslate nohighlight">\(E(3)\)</span>-equivariant, but they usually follow the same principle of only using distances in their computations. If you want to read up on this you can take a look at these papers</p>
<ul class="simple">
<li><p><a class="reference external" href="https://proceedings.mlr.press/v139/satorras21a.html">E(n) Equivariant Graph Neural Networks</a></p></li>
<li><p><a class="reference external" href="https://proceedings.neurips.cc/paper/2020/file/15231a7ce4ba789d13b722cc5c955834-Paper.pdf">SE(3) Transformer</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2202.02541">TorchMD-Net</a></p></li>
</ul>
<div class="line-block">
<div class="line"><br/></div>
<div class="line"><span class="math notranslate nohighlight">\(~^1\)</span> multi-layer perceptrons (MLPS) are stacks of multiple fully connected layers with non-linear activation functions (also see <strong>Talktorial T022</strong>)</div>
</div>
</section>
<section id="The-QM9-dataset">
<h3 id="The-QM9-dataset">The QM9 dataset<a class="headerlink" href="#The-QM9-dataset" title="Permalink to this heading">¶</a></h3>
<p>The QM9 dataset <a class="reference external" href="https://www.nature.com/articles/sdata201422/?ref=https://githubhelp.com">[1]</a> <a class="reference external" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/datasets.html#torch_geometric.datasets.QM9">[2]</a> is part of the <a class="reference external" href="https://pubs.rsc.org/en/content/articlehtml/2018/sc/c7sc02664a">MoleculeNet benchmark</a> and consists of ~130k small, organic molecules with up to 9 heavy atoms. It also includes targets for various geometric, energetic, electronic and thermodynamic properties. Crucially,
it also includes atom 3D coordinates, which makes it suitable for this talktorial.</p>
</section>
</section>
<section id="id1">
<h2 id="id1">Practical<a class="headerlink" href="#id1" title="Permalink to this heading">¶</a></h2>
<p>For the practical part, we will be working with a <a class="reference external" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/datasets.html#torch_geometric.datasets.QM9">version of QM9 that is already included in PyTorch Geometric</a>, as implementing the dataset from scratch would go beyond the scope of this talktorial. We will just inspect the data and briefly discuss how point clouds can be represented by several tensors. Then we will demonstrate how one could use plain GNNs to work with point clouds and why
this approach would yield models that are not <span class="math notranslate nohighlight">\(\text{E}(3)\)</span> invariant/equivariant. Finally, you will learn how to implement, train and evaluate equivariant GNNs.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">operator</span>
<span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">chain</span><span class="p">,</span> <span class="n">product</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">,</span> <span class="n">NamedTuple</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">LongTensor</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">sys</span>
<span class="k">if</span> <span class="n">sys</span><span class="o">.</span><span class="n">platform</span><span class="o">.</span><span class="n">startswith</span><span class="p">((</span><span class="s2">"linux"</span><span class="p">,</span> <span class="s2">"darwin"</span><span class="p">)):</span>
    <span class="o">!</span>mamba<span class="w"> </span>install<span class="w"> </span>-q<span class="w"> </span>-y<span class="w"> </span>-c<span class="w"> </span>pyg<span class="w"> </span>pyg
    <span class="o">!</span>mamba<span class="w"> </span>install<span class="w"> </span>-q<span class="w"> </span>-y<span class="w"> </span>-c<span class="w"> </span>conda-forge<span class="w"> </span>pytorch_scatter
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch_geometric</span>
<span class="kn">from</span> <span class="nn">torch_geometric.transforms</span> <span class="kn">import</span> <span class="n">BaseTransform</span><span class="p">,</span> <span class="n">Compose</span>
<span class="kn">from</span> <span class="nn">torch_geometric.datasets</span> <span class="kn">import</span> <span class="n">QM9</span>
<span class="kn">from</span> <span class="nn">torch_geometric.data</span> <span class="kn">import</span> <span class="n">Data</span>
<span class="kn">from</span> <span class="nn">torch_geometric.loader</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">torch_geometric.data</span> <span class="kn">import</span> <span class="n">Dataset</span>
<span class="kn">from</span> <span class="nn">torch_geometric.nn.aggr</span> <span class="kn">import</span> <span class="n">SumAggregation</span>
<span class="kn">import</span> <span class="nn">torch_geometric.nn</span> <span class="k">as</span> <span class="nn">geom_nn</span>

<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">torch_scatter</span> <span class="kn">import</span> <span class="n">scatter</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set path to this notebook</span>
<span class="n">HERE</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">_dh</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="n">DATA</span> <span class="o">=</span> <span class="n">HERE</span> <span class="o">/</span> <span class="s2">"data"</span>
</pre></div>
</div>
</div>
<section id="Visualization-of-point-clouds">
<h3 id="Visualization-of-point-clouds">Visualization of point clouds<a class="headerlink" href="#Visualization-of-point-clouds" title="Permalink to this heading">¶</a></h3>
<p>The following auxiliary function <code class="docutils literal notranslate"><span class="pre">plot_point_cloud_3d</span></code> will see heavy use later on for the visualization of model input and model outputs. Note that to visualize molecules rather than their tensor representations used for machine learning, it would be better to use e.g. <code class="docutils literal notranslate"><span class="pre">RDKit</span></code> or <code class="docutils literal notranslate"><span class="pre">NGLview</span></code>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">to_perceived_brightness</span><span class="p">(</span><span class="n">rgb</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Auxiliary function, useful for choosing label colors</span>
<span class="sd">    with good visibility</span>
<span class="sd">    """</span>
    <span class="n">r</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">rgb</span>
    <span class="k">return</span> <span class="mf">0.1</span> <span class="o">*</span> <span class="n">r</span> <span class="o">+</span> <span class="mf">0.8</span> <span class="o">*</span> <span class="n">g</span> <span class="o">+</span> <span class="mf">0.1</span>


<span class="k">def</span> <span class="nf">plot_point_cloud_3d</span><span class="p">(</span>
    <span class="n">fig</span><span class="p">:</span> <span class="n">mpl</span><span class="o">.</span><span class="n">figure</span><span class="o">.</span><span class="n">Figure</span><span class="p">,</span>
    <span class="n">ax_pos</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">color</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">pos</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">cmap</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">"plasma"</span><span class="p">,</span>
    <span class="n">point_size</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">180.0</span><span class="p">,</span>
    <span class="n">label_axes</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">annotate_points</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">remove_axes_ticks</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">cbar_label</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">""</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">mpl</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">Axis</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Visualize colored 3D point clouds.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    fig : mpl.figure.Figure</span>
<span class="sd">        The figure for which a new axis object is added for plotting</span>
<span class="sd">    ax_pos : int</span>
<span class="sd">        Three-digit integer specifying axis layout and position</span>
<span class="sd">        (see docs for `mpl.figure.Figure.add_subplot`)</span>
<span class="sd">    color : np.ndarray</span>
<span class="sd">        The point colors as a float array of shape `(N,)`</span>
<span class="sd">    pos : np.ndarray</span>
<span class="sd">        The point xyz-coordinates as an array</span>
<span class="sd">    cmap : str, optional</span>
<span class="sd">        String identifier for a matplotlib colormap.</span>
<span class="sd">        Is used to map the values in `color` to rgb colors.</span>
<span class="sd">        , by default "plasma"</span>
<span class="sd">    point_size : float, optional</span>
<span class="sd">        The size of plotted points, by default 180.0</span>
<span class="sd">    label_axes : bool, optional</span>
<span class="sd">        whether to label x,y and z axes by default False</span>
<span class="sd">    annotate_points : bool, optional</span>
<span class="sd">        whether to label points with their index, by default True</span>
<span class="sd">    cbar_label : str, optional</span>
<span class="sd">        label for the colorbar, by default ""</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    mpl.axis.Axis</span>
<span class="sd">        The new axis object for the 3D point cloud plot.</span>
<span class="sd">    """</span>
    <span class="n">cmap</span> <span class="o">=</span> <span class="n">mpl</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="n">cmap</span><span class="p">)</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="n">ax_pos</span><span class="p">,</span> <span class="n">projection</span><span class="o">=</span><span class="s2">"3d"</span><span class="p">)</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span> <span class="o">=</span> <span class="n">pos</span>
    <span class="k">if</span> <span class="n">remove_axes_ticks</span><span class="p">:</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">([])</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">([])</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_zticklabels</span><span class="p">([])</span>
    <span class="k">if</span> <span class="n">label_axes</span><span class="p">:</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">"$x$ coordinate"</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">"$y$ coordinate"</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_zlabel</span><span class="p">(</span><span class="s2">"$z$ coordinate"</span><span class="p">)</span>
    <span class="n">sc</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">point_size</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">sc</span><span class="p">,</span> <span class="n">location</span><span class="o">=</span><span class="s2">"bottom"</span><span class="p">,</span> <span class="n">shrink</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="n">cbar_label</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">annotate_points</span><span class="p">:</span>
        <span class="n">_colors</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">cmap</span><span class="p">(</span><span class="n">color</span><span class="p">)</span>
        <span class="n">rgb</span> <span class="o">=</span> <span class="n">_colors</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span>
        <span class="n">brightness</span> <span class="o">=</span> <span class="n">to_perceived_brightness</span><span class="p">(</span><span class="n">rgb</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">xi</span><span class="p">,</span> <span class="n">yi</span><span class="p">,</span> <span class="n">zi</span><span class="p">,</span> <span class="n">li</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">brightness</span><span class="p">)):</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">xi</span><span class="p">,</span> <span class="n">yi</span><span class="p">,</span> <span class="n">zi</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="kc">None</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span> <span class="o">-</span> <span class="n">li</span><span class="p">]</span> <span class="o">*</span> <span class="mi">3</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s2">"center"</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s2">"center"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ax</span>


<span class="c1"># testing</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>

<span class="k">for</span> <span class="n">ax_pos</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">221</span><span class="p">,</span> <span class="mi">222</span><span class="p">,</span> <span class="mi">223</span><span class="p">,</span> <span class="mi">224</span><span class="p">]:</span>
    <span class="n">pos</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
    <span class="n">color</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
    <span class="n">plot_point_cloud_3d</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax_pos</span><span class="p">,</span> <span class="n">color</span><span class="p">,</span> <span class="n">pos</span><span class="p">)</span>

<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">"Random test point clouds"</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/tmp/ipykernel_51907/441942460.py:53: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.
  cmap = mpl.cm.get_cmap(cmap)
/tmp/ipykernel_51907/441942460.py:84: UserWarning: Tight layout not applied. The left and right margins cannot be made large enough to accommodate all axes decorations.
  fig.tight_layout()
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/talktorials_T036_e3_equivariant_gnn_20_1.png" src="../_images/talktorials_T036_e3_equivariant_gnn_20_1.png"/>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_model_input</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="n">Data</span><span class="p">,</span> <span class="n">fig</span><span class="p">:</span> <span class="n">mpl</span><span class="o">.</span><span class="n">figure</span><span class="o">.</span><span class="n">Figure</span><span class="p">,</span> <span class="n">ax_pos</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">mpl</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">Axis</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Plots 3D point cloud model input represented by a torch geometric</span>
<span class="sd">    `Data` object. Use atomic numbers as colors.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : Data</span>
<span class="sd">        The 3D point cloud. Must have atomic numbers `z` and 2D coordinates `pos`</span>
<span class="sd">        properties that are not `None`.</span>
<span class="sd">    fig: mpl.figure.Figure</span>
<span class="sd">        The maptlotlib figure to plot on.</span>
<span class="sd">    ax_pos:</span>
<span class="sd">        Three-digit integer specifying axis layout and position</span>
<span class="sd">        (see docs for `mpl.figure.Figure.add_subplot`).</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    mpl.axis.Axis</span>
<span class="sd">        The newly created axis object.</span>
<span class="sd">    """</span>
    <span class="n">color</span><span class="p">,</span> <span class="n">pos</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">z</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">pos</span>
    <span class="n">color</span> <span class="o">=</span> <span class="n">color</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="n">pos</span> <span class="o">=</span> <span class="n">pos</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">plot_point_cloud_3d</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax_pos</span><span class="p">,</span> <span class="n">color</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">cbar_label</span><span class="o">=</span><span class="s2">"Atomic number"</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">plot_model_embedding</span><span class="p">(</span>
    <span class="n">data</span><span class="p">:</span> <span class="n">Data</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Data</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">],</span> <span class="n">fig</span><span class="p">:</span> <span class="n">mpl</span><span class="o">.</span><span class="n">figure</span><span class="o">.</span><span class="n">Figure</span><span class="p">,</span> <span class="n">ax_pos</span><span class="p">:</span> <span class="nb">int</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">mpl</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">Axis</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Same as `plot_model_input` but instead of node features as color,</span>
<span class="sd">    first apply a GNN model to obtain colors from node embeddings.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : Data</span>
<span class="sd">        the model input. Must have 3D coordinates `pos`</span>
<span class="sd">        an atomic number `z` properties that are not `None`.</span>
<span class="sd">    model : Callable[[Data], Tensor]</span>
<span class="sd">        the model must take Data objects as input and return node embeddings</span>
<span class="sd">        as a Tensor output.</span>
<span class="sd">    fig: mpl.figure.Figure</span>
<span class="sd">        The maptlotlib figure to plot on.</span>
<span class="sd">    ax_pos:</span>
<span class="sd">        Three-digit integer specifying axis layout and position</span>
<span class="sd">        (see docs for `mpl.figure.Figure.add_subplot`).</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    mpl.axis.Axis</span>
<span class="sd">        The newly created axis object.</span>
<span class="sd">    """</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">pos</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">pos</span>
    <span class="n">color</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="n">pos</span> <span class="o">=</span> <span class="n">pos</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">plot_point_cloud_3d</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax_pos</span><span class="p">,</span> <span class="n">color</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">cbar_label</span><span class="o">=</span><span class="s2">"Atom embedding (1D)"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="Set-up-and-inspect-the-QM9-dataset">
<h3 id="Set-up-and-inspect-the-QM9-dataset">Set up and inspect the QM9 dataset<a class="headerlink" href="#Set-up-and-inspect-the-QM9-dataset" title="Permalink to this heading">¶</a></h3>
<section id="Preprocessing">
<h4 id="Preprocessing">Preprocessing<a class="headerlink" href="#Preprocessing" title="Permalink to this heading">¶</a></h4>
<p>For the sake of this tutorial, we will restrict ourselves to small molecules with at most 8 heavy atoms. Due to our decision to ignore structural information and treat molecules as point clouds, where every atom interacts with every other atom, we also need to extend the torch geometric <code class="docutils literal notranslate"><span class="pre">Data</span></code> objects with additional adjacency information that represents a complete graph without self-loops.</p>
<p>For performance reasons, both of these steps are performed <em>once</em> when pre-processing the raw data using the <code class="docutils literal notranslate"><span class="pre">pre_filter</span></code> and <code class="docutils literal notranslate"><span class="pre">pre_transform</span></code> keyword arguments of the dataset class.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">num_heavy_atoms</span><span class="p">(</span><span class="n">qm9_data</span><span class="p">:</span> <span class="n">Data</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Count the number of heavy atoms in a torch geometric</span>
<span class="sd">    Data object.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    qm9_data : Data</span>
<span class="sd">        A pytorch geometric qm9 data object representing a small molecule</span>
<span class="sd">         where atomic numbers are stored in a</span>
<span class="sd">        tensor-valued attribute `qm9_data.z`</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    int</span>
<span class="sd">        The number of heavy atoms in the molecule.</span>
<span class="sd">    """</span>
    <span class="c1"># every atom with atomic number other than 1 is heavy</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">qm9_data</span><span class="o">.</span><span class="n">z</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">complete_edge_index</span><span class="p">(</span><span class="n">n</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">LongTensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Constructs a complete edge index.</span>

<span class="sd">    NOTE: representing complete graphs</span>
<span class="sd">    with sparse edge tensors is arguably a bad idea</span>
<span class="sd">    due to performance reasons, but for this tutorial it'll do.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n : int</span>
<span class="sd">        the number of nodes in the graph.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    LongTensor</span>
<span class="sd">        A PyTorch `edge_index` represents a complete graph with n nodes,</span>
<span class="sd">        without self-loops. Shape (2, n).</span>
<span class="sd">    """</span>
    <span class="c1"># filter removes self loops</span>
    <span class="n">edges</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">e</span><span class="p">:</span> <span class="n">e</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">e</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">product</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">),</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">))))</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">edges</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>


<span class="k">def</span> <span class="nf">add_complete_graph_edge_index</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="n">Data</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Data</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    On top of any edge information already there,</span>
<span class="sd">    add a second edge index that represents</span>
<span class="sd">    the complete graph corresponding to a  given</span>
<span class="sd">    torch geometric data object</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : Data</span>
<span class="sd">        The torch geometric data object.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Data</span>
<span class="sd">        The torch geometric `Data` object with a new</span>
<span class="sd">        attribute `complete_edge_index` as described above.</span>
<span class="sd">    """</span>
    <span class="n">data</span><span class="o">.</span><span class="n">complete_edge_index</span> <span class="o">=</span> <span class="n">complete_edge_index</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">data</span>


<span class="c1">#</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">QM9</span><span class="p">(</span>
    <span class="n">DATA</span><span class="p">,</span>
    <span class="c1"># Filter out molecules with more than 8 heavy atoms</span>
    <span class="n">pre_filter</span><span class="o">=</span><span class="k">lambda</span> <span class="n">data</span><span class="p">:</span> <span class="n">num_heavy_atoms</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">9</span><span class="p">,</span>
    <span class="c1"># implement point cloud adjacency as a complete graph</span>
    <span class="n">pre_transform</span><span class="o">=</span><span class="n">add_complete_graph_edge_index</span><span class="p">,</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Num. examples in QM9 restricted to molecules with at most 8 heavy atoms: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Num. examples in QM9 restricted to molecules with at most 8 heavy atoms: 21800
</pre></div></div>
</div>
<p>NOTE: executing the above cell for the first time first downloads and then processes the raw data, which <strong>might take a while</strong>.</p>
<p>Indexing the dataset we just created returns a single Pytorch Geometric <code class="docutils literal notranslate"><span class="pre">Data</span></code> object representing one molecular graph/point cloud. You can think of these objects as dictionaries with some extra utility methods already implemented.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="c1"># This displays all named data attributes, and their shapes (in the case of tensors), or values (in the case of other data).</span>
<span class="n">data</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Data(x=[5, 11], edge_index=[2, 8], edge_attr=[8, 4], y=[1, 19], pos=[5, 3], z=[5], name='gdb_1', idx=[1], complete_edge_index=[2, 20])
</pre></div></div>
</div>
<p>For index 0 (name <code class="docutils literal notranslate"><span class="pre">gdb_1</span></code>) this should be the molecule CH4. We can check this by looking into the atomic numbers stored in the attributed named <code class="docutils literal notranslate"><span class="pre">z</span></code></p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">z</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
tensor([6, 1, 1, 1, 1])
</pre></div></div>
</div>
<p>For molecules with <code class="docutils literal notranslate"><span class="pre">N</span></code> atoms and <code class="docutils literal notranslate"><span class="pre">M</span></code> (covalent) bonds, the data objects also contain named tensors of shape</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Data.x</span></code>: <code class="docutils literal notranslate"><span class="pre">(N,</span> <span class="pre">d_node)</span></code> node-level features (e.g. formal charge, membership to aromatic rings, chirality, …), but we will ignore them here and just use atomic numbers.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Data.y</span></code>: <code class="docutils literal notranslate"><span class="pre">(19,)</span></code> regression targets</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Data.edge_index</span></code>: <code class="docutils literal notranslate"><span class="pre">(2,</span> <span class="pre">M)</span></code> edges between atoms derived from covalent bonds, stored as source and target node index pairs.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Data.edge_attr</span></code>: <code class="docutils literal notranslate"><span class="pre">(M,</span> <span class="pre">d_edge)</span></code> contains bond features (e.g. bond type, ring-membership, …)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Data.pos</span></code>: <code class="docutils literal notranslate"><span class="pre">(N,</span> <span class="pre">3)</span></code> most interesting to us, atom 3D coordinates.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Data.complete_edge_index</span></code>: <code class="docutils literal notranslate"><span class="pre">(2,</span> <span class="pre">(N-1)^2)</span></code>: the complete graph edge index (without self-loops) we added earlier.</p></li>
</ul>
<p>The input to our (point cloud) model we will implement later can be visualized using just <code class="docutils literal notranslate"><span class="pre">Data.z</span></code> as color and <code class="docutils literal notranslate"><span class="pre">Data.pos</span></code> as scatter plot positions. Note: the alpha channel of colors is used to convey depth-information.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">pos</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">decimals</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
tensor([[-0.0100,  1.0900,  0.0100],
        [ 0.0000, -0.0100,  0.0000],
        [ 1.0100,  1.4600,  0.0000],
        [-0.5400,  1.4500, -0.8800],
        [-0.5200,  1.4400,  0.9100]])
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">plot_model_input</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">fig</span><span class="p">,</span> <span class="mi">111</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"CH$_4$ (Methane)"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/tmp/ipykernel_51907/441942460.py:53: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.
  cmap = mpl.cm.get_cmap(cmap)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/talktorials_T036_e3_equivariant_gnn_32_1.png" src="../_images/talktorials_T036_e3_equivariant_gnn_32_1.png"/>
</div>
</div>
</section>
<section id="Atomic-number-distribution-and-point-cloud-size">
<h4 id="Atomic-number-distribution-and-point-cloud-size">Atomic number distribution and point cloud size<a class="headerlink" href="#Atomic-number-distribution-and-point-cloud-size" title="Permalink to this heading">¶</a></h4>
<p>Now that our dataset is set up, and we have a basic understanding of how molecules are represented, we can try to visualize the properties of the entire dataset. Let us first look at the distribution of node-level features (atomic numbers) and the point cloud size (number of atoms) aggregated over the entire dataset.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax_atoms</span><span class="p">,</span> <span class="n">ax_graph_size</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="c1"># ax_atoms.hist(dataset.data.z[dataset.data.z != 1])</span>
<span class="n">ax_atoms</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">z</span><span class="p">)</span>
<span class="n">ax_atoms</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">"Atomic number $z$"</span><span class="p">)</span>
<span class="n">ax_atoms</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">"Count"</span><span class="p">)</span>
<span class="n">num_nodes</span> <span class="o">=</span> <span class="p">[</span><span class="n">dataset</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">num_nodes</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">))]</span>
<span class="n">ax_graph_size</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">num_nodes</span><span class="p">)</span>
<span class="n">ax_graph_size</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">"Graph size (#nodes)"</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">"Aggregated molecular point cloud properties"</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
~/.miniconda3/envs/teachopencadd/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/talktorials_T036_e3_equivariant_gnn_34_1.png" src="../_images/talktorials_T036_e3_equivariant_gnn_34_1.png"/>
</div>
</div>
<p>We can see that while fluorine atoms (number 9) show up in the data, they are heavily underrepresented (the bar at <span class="math notranslate nohighlight">\(z=9\)</span> is barely visible), which is not a nice property that is likely since we shrunk the dataset. The number of atoms seems to be roughly normally distributed, which is nice.</p>
</section>
<section id="Data-split,-distribution-of-regression-target-electronic-spatial-extent">
<h4 id="Data-split,-distribution-of-regression-target-electronic-spatial-extent">Data split, distribution of regression target electronic spatial extent<a class="headerlink" href="#Data-split,-distribution-of-regression-target-electronic-spatial-extent" title="Permalink to this heading">¶</a></h4>
<p>Next, we will implement data splitting, choose a regression target and visualize the split w.r.t. to this target. Out of the 19 regression targets included in QM9, we’ll focus on <em>electronic spatial extent</em>, which, simply put, describes the volume of a molecule, so it should be a good fit for methods that use 3D information. Let us now start with implementing a <em>data module</em> that takes care of train/val/test splits and of indexing the correct target.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">QM9DataModule</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">train_ratio</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span>
        <span class="n">val_ratio</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
        <span class="n">test_ratio</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
        <span class="n">target_idx</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
        <span class="n">seed</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">420</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Encapsulates everything related to the dataset</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        train_ratio : float, optional</span>
<span class="sd">            fraction of data used for training, by default 0.8</span>
<span class="sd">        val_ratio : float, optional</span>
<span class="sd">            fraction of data used for validation, by default 0.1</span>
<span class="sd">        test_ratio : float, optional</span>
<span class="sd">            fraction of data used for testing, by default 0.1</span>
<span class="sd">        target_idx : int, optional</span>
<span class="sd">            index of the target (see torch geometric docs), by default 5 (electronic spatial extent)</span>
<span class="sd">            (https://pytorch-geometric.readthedocs.io/en/latest/modules/datasets.html?highlight=qm9#torch_geometric.datasets.QM9)</span>
<span class="sd">        seed : float, optional</span>
<span class="sd">            random seed for data split, by default 420</span>
<span class="sd">        """</span>
        <span class="k">assert</span> <span class="nb">sum</span><span class="p">([</span><span class="n">train_ratio</span><span class="p">,</span> <span class="n">val_ratio</span><span class="p">,</span> <span class="n">test_ratio</span><span class="p">])</span> <span class="o">==</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_idx</span> <span class="o">=</span> <span class="n">target_idx</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_examples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">())</span>
        <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shuffled_index</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_examples</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_split</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shuffled_index</span><span class="p">[:</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_examples</span> <span class="o">*</span> <span class="n">train_ratio</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_split</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shuffled_index</span><span class="p">[</span>
            <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_examples</span> <span class="o">*</span> <span class="n">train_ratio</span><span class="p">)</span> <span class="p">:</span> <span class="nb">int</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">num_examples</span> <span class="o">*</span> <span class="p">(</span><span class="n">train_ratio</span> <span class="o">+</span> <span class="n">val_ratio</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_split</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shuffled_index</span><span class="p">[</span>
            <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_examples</span> <span class="o">*</span> <span class="p">(</span><span class="n">train_ratio</span> <span class="o">+</span> <span class="n">val_ratio</span><span class="p">))</span> <span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_examples</span>
        <span class="p">]</span>

    <span class="k">def</span> <span class="nf">dataset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">QM9</span><span class="p">:</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">QM9</span><span class="p">(</span>
            <span class="n">DATA</span><span class="p">,</span>
            <span class="n">pre_filter</span><span class="o">=</span><span class="k">lambda</span> <span class="n">data</span><span class="p">:</span> <span class="n">num_heavy_atoms</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">9</span><span class="p">,</span>
            <span class="n">pre_transform</span><span class="o">=</span><span class="n">add_complete_graph_edge_index</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">dataset</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">y</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_idx</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">dataset</span>

    <span class="k">def</span> <span class="nf">loader</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">split</span><span class="p">,</span> <span class="o">**</span><span class="n">loader_kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataLoader</span><span class="p">:</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">()[</span><span class="n">split</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="o">**</span><span class="n">loader_kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">train_loader</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">loader_kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataLoader</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">loader</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_split</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">loader_kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">val_loader</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">loader_kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataLoader</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">loader</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">val_split</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">loader_kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">test_loader</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">loader_kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataLoader</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">loader</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test_split</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">loader_kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Now we can easily plot the target across the data split.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data_module</span> <span class="o">=</span> <span class="n">QM9DataModule</span><span class="p">()</span>

<span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">data_module</span><span class="o">.</span><span class="n">dataset</span><span class="p">()</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="n">target</span><span class="p">[</span><span class="n">data_module</span><span class="o">.</span><span class="n">train_split</span><span class="p">],</span>
        <span class="n">target</span><span class="p">[</span><span class="n">data_module</span><span class="o">.</span><span class="n">val_split</span><span class="p">],</span>
        <span class="n">target</span><span class="p">[</span><span class="n">data_module</span><span class="o">.</span><span class="n">test_split</span><span class="p">],</span>
    <span class="p">]</span>
<span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">([</span><span class="s2">"Train"</span><span class="p">,</span> <span class="s2">"Val"</span><span class="p">,</span> <span class="s2">"Test"</span><span class="p">])</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">"Electronic spatial extent $\langle R^2 </span><span class="se">\\</span><span class="s2">rangle$"</span><span class="p">)</span>

<span class="k">for</span> <span class="n">label</span><span class="p">,</span> <span class="n">split</span> <span class="ow">in</span> <span class="p">{</span>
    <span class="s2">"Train"</span><span class="p">:</span> <span class="n">data_module</span><span class="o">.</span><span class="n">train_split</span><span class="p">,</span>
    <span class="s2">"Val"</span><span class="p">:</span> <span class="n">data_module</span><span class="o">.</span><span class="n">val_split</span><span class="p">,</span>
    <span class="s2">"Test"</span><span class="p">:</span> <span class="n">data_module</span><span class="o">.</span><span class="n">test_split</span><span class="p">,</span>
<span class="p">}</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">split</span><span class="p">,</span> <span class="n">target</span><span class="p">[</span><span class="n">split</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">"Example index"</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">"Random data split - target distribution"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
~/.miniconda3/envs/teachopencadd/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Text(0.5, 0.98, 'Random data split - target distribution')
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/talktorials_T036_e3_equivariant_gnn_39_2.png" src="../_images/talktorials_T036_e3_equivariant_gnn_39_2.png"/>
</div>
</div>
<p>You should be able to observe that random splits are typically very homogenous, which means measuring generalization capabilities with them can yield deceivingly good results.</p>
</section>
</section>
<section id="Model-implementation">
<h3 id="Model-implementation">Model implementation<a class="headerlink" href="#Model-implementation" title="Permalink to this heading">¶</a></h3>
<section id="Plain-%22naive-Euclidean%22-GNN">
<h4 id="Plain-%22naive-Euclidean%22-GNN">Plain “naive Euclidean” GNN<a class="headerlink" href="#Plain-%22naive-Euclidean%22-GNN" title="Permalink to this heading">¶</a></h4>
<p>A naive way to incorporate 3D coordinates into a GNN for molecular graphs would be to interpret them as atom-level features that are simply combined with the other features. It is easy to implement a simple baseline model which does exactly this (see <strong>Talktorial T035</strong>). For its message-passing topology, our implementation uses the edges induced by bonds between atoms.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">NaiveEuclideanGNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">hidden_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">num_layers</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">num_spatial_dims</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">final_embedding_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">act</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># NOTE nn.Embedding acts like a lookup table.</span>
        <span class="c1"># Here we use it to store each atomic number in [0,100]</span>
        <span class="c1"># a learnable, fixed-size vector representation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f_initial_embed</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f_pos_embed</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_spatial_dims</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f_combine</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">hidden_channels</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">),</span> <span class="n">act</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">final_embedding_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">final_embedding_size</span> <span class="o">=</span> <span class="n">hidden_channels</span>

        <span class="c1"># Graph isomorphism network as main GNN</span>
        <span class="c1"># (see Talktorial 034)</span>
        <span class="c1"># takes care of message passing and</span>
        <span class="c1"># Learning node-level embeddings</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gnn</span> <span class="o">=</span> <span class="n">geom_nn</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">GIN</span><span class="p">(</span>
            <span class="n">in_channels</span><span class="o">=</span><span class="n">hidden_channels</span><span class="p">,</span>
            <span class="n">hidden_channels</span><span class="o">=</span><span class="n">hidden_channels</span><span class="p">,</span>
            <span class="n">out_channels</span><span class="o">=</span><span class="n">final_embedding_size</span><span class="p">,</span>
            <span class="n">num_layers</span><span class="o">=</span><span class="n">num_layers</span><span class="p">,</span>
            <span class="n">act</span><span class="o">=</span><span class="n">act</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># modules required for aggregating node embeddings</span>
        <span class="c1"># into graph embeddings and making graph-level predictions</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">aggregation</span> <span class="o">=</span> <span class="n">geom_nn</span><span class="o">.</span><span class="n">aggr</span><span class="o">.</span><span class="n">SumAggregation</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f_predict</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">final_embedding_size</span><span class="p">,</span> <span class="n">final_embedding_size</span><span class="p">),</span>
            <span class="n">act</span><span class="p">,</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">final_embedding_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">Data</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="c1"># initial atomic number embedding and embedding od positional information</span>
        <span class="n">atom_embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_initial_embed</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">z</span><span class="p">)</span>
        <span class="n">pos_embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_pos_embed</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">pos</span><span class="p">)</span>

        <span class="c1"># treat both as plain node-level features and combine into initial node-level</span>
        <span class="c1"># embedddings</span>
        <span class="n">initial_node_embed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_combine</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">atom_embedding</span><span class="p">,</span> <span class="n">pos_embedding</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>

        <span class="c1"># message passing</span>
        <span class="c1"># NOTE in contrast to the EGNN implemented later, this model does use bond information</span>
        <span class="c1"># i.e., data.egde_index stems from the bond adjacency matrix</span>
        <span class="n">node_embed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gnn</span><span class="p">(</span><span class="n">initial_node_embed</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">edge_index</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">node_embed</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">Data</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="n">node_embed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">aggr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">aggregation</span><span class="p">(</span><span class="n">node_embed</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_predict</span><span class="p">(</span><span class="n">aggr</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="Demo:-Plain-GNNs-are-not-\text{E(3)}-invariant">
<h4 id="Demo:-Plain-GNNs-are-not-\text{E(3)}-invariant">Demo: Plain GNNs are not <span class="math notranslate nohighlight">\(\text{E(3)}\)</span>-invariant<a class="headerlink" href="#Demo:-Plain-GNNs-are-not-\text{E(3)}-invariant" title="Permalink to this heading">¶</a></h4>
<p>However, this approach is problematic because the corresponding atom embeddings of a regular GNN (from which we would also derive our final predictions) will not be <span class="math notranslate nohighlight">\(\text{E}(3)\)</span>-invariant. This can be demonstrated easily:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># use rotations along z-axis as demo e(3) transformation</span>
<span class="k">def</span> <span class="nf">rotation_matrix_z</span><span class="p">(</span><span class="n">theta</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Generates a rotation matrix and returns</span>
<span class="sd">    a corresponing tensor. The rotation is about the $z$-axis.</span>
<span class="sd">    (https://en.wikipedia.org/wiki/Rotation_matrix)</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    theta : float</span>
<span class="sd">        the angle of rotation.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Tensor</span>
<span class="sd">        the rotation matrix as float tensor.</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
        <span class="p">[</span>
            <span class="p">[</span><span class="n">math</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">theta</span><span class="p">),</span> <span class="o">-</span><span class="n">math</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">theta</span><span class="p">),</span> <span class="mi">0</span><span class="p">],</span>
            <span class="p">[</span><span class="n">math</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">theta</span><span class="p">),</span> <span class="n">math</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">theta</span><span class="p">),</span> <span class="mi">0</span><span class="p">],</span>
            <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
        <span class="p">]</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
<p><em>NOTE</em>: you may need to run the cell below multiple times to find a model initialization for which non-invariance can easily be observed.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Some data points from qm9</span>
<span class="n">sample_data</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="mi">800</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>

<span class="c1"># apply an E(3) transformation</span>
<span class="n">rotated_sample_data</span> <span class="o">=</span> <span class="n">sample_data</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
<span class="n">rotated_sample_data</span><span class="o">.</span><span class="n">pos</span> <span class="o">=</span> <span class="n">rotated_sample_data</span><span class="o">.</span><span class="n">pos</span> <span class="o">@</span> <span class="n">rotation_matrix_z</span><span class="p">(</span><span class="mi">45</span><span class="p">)</span>

<span class="c1"># initialize a model with 2 hidden layers, 32 hidden channels,</span>
<span class="c1"># that outputs 1-dimensional node embeddings</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">NaiveEuclideanGNN</span><span class="p">(</span>
    <span class="n">hidden_channels</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
    <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">num_spatial_dims</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">final_embedding_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># make a plot that demonstrates non-equivariance</span>
<span class="c1"># fig, axes = plt.subplots(2, 2, figsize=(8,8), sharex=True, sharey=True)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>

<span class="n">ax1</span> <span class="o">=</span> <span class="n">plot_model_input</span><span class="p">(</span><span class="n">sample_data</span><span class="p">,</span> <span class="n">fig</span><span class="p">,</span> <span class="mi">221</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"Sample input $(X, Z)$"</span><span class="p">)</span>

<span class="n">ax2</span> <span class="o">=</span> <span class="n">plot_model_input</span><span class="p">(</span><span class="n">rotated_sample_data</span><span class="p">,</span> <span class="n">fig</span><span class="p">,</span> <span class="mi">222</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"Rotated input $(X, g(Z))$"</span><span class="p">)</span>

<span class="n">ax3</span> <span class="o">=</span> <span class="n">plot_model_embedding</span><span class="p">(</span><span class="n">sample_data</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">encode</span><span class="p">,</span> <span class="n">fig</span><span class="p">,</span> <span class="mi">223</span><span class="p">)</span>
<span class="n">ax3</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"Model output for $(X, Z)$"</span><span class="p">)</span>

<span class="n">ax4</span> <span class="o">=</span> <span class="n">plot_model_embedding</span><span class="p">(</span><span class="n">rotated_sample_data</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">encode</span><span class="p">,</span> <span class="n">fig</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span>
<span class="n">ax4</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"Model output for $(X, g(Z))$"</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/tmp/ipykernel_51907/441942460.py:53: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.
  cmap = mpl.cm.get_cmap(cmap)
/tmp/ipykernel_51907/2912899843.py:32: UserWarning: Tight layout not applied. The left and right margins cannot be made large enough to accommodate all axes decorations.
  fig.tight_layout()
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/talktorials_T036_e3_equivariant_gnn_47_1.png" src="../_images/talktorials_T036_e3_equivariant_gnn_47_1.png"/>
</div>
</div>
<p>When executing the above cells a few times, we can observe that rotating the molecule may <em>significantly</em> alter the atom embeddings obtained from the plain GNN model.</p>
</section>
<section id="EGNN-model">
<h4 id="EGNN-model">EGNN model<a class="headerlink" href="#EGNN-model" title="Permalink to this heading">¶</a></h4>
<p>We now implement an <span class="math notranslate nohighlight">\(\text{E}(n)\)</span>-invariant GNN based on the principles outlined in the theory section.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">EquivariantMPLayer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">in_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">hidden_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">act</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">act</span> <span class="o">=</span> <span class="n">act</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">residual_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="c1"># Messages will consist of two (source and target) node embeddings and a scalar distance</span>
        <span class="n">message_input_size</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">in_channels</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="c1"># equation (3) "phi_l" NN</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">message_mlp</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">message_input_size</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">),</span>
            <span class="n">act</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># equation (4) "psi_l" NN</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">node_update_mlp</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_channels</span> <span class="o">+</span> <span class="n">hidden_channels</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">),</span>
            <span class="n">act</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">node_message_function</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">source_node_embed</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>  <span class="c1"># h_i</span>
        <span class="n">target_node_embed</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>  <span class="c1"># h_j</span>
        <span class="n">node_dist</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>  <span class="c1"># d_ij</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="c1"># implements equation (3)</span>
        <span class="n">message_repr</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">source_node_embed</span><span class="p">,</span> <span class="n">target_node_embed</span><span class="p">,</span> <span class="n">node_dist</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">message_mlp</span><span class="p">(</span><span class="n">message_repr</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">compute_distances</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node_pos</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">:</span> <span class="n">LongTensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="n">row</span><span class="p">,</span> <span class="n">col</span> <span class="o">=</span> <span class="n">edge_index</span>
        <span class="n">xi</span><span class="p">,</span> <span class="n">xj</span> <span class="o">=</span> <span class="n">node_pos</span><span class="p">[</span><span class="n">row</span><span class="p">],</span> <span class="n">node_pos</span><span class="p">[</span><span class="n">col</span><span class="p">]</span>
        <span class="c1"># relative squared distance</span>
        <span class="c1"># implements equation (2) ||X_i - X_j||^2</span>
        <span class="n">rsdist</span> <span class="o">=</span> <span class="p">(</span><span class="n">xi</span> <span class="o">-</span> <span class="n">xj</span><span class="p">)</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">rsdist</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">node_embed</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">node_pos</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">edge_index</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="n">row</span><span class="p">,</span> <span class="n">col</span> <span class="o">=</span> <span class="n">edge_index</span>
        <span class="n">dist</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_distances</span><span class="p">(</span><span class="n">node_pos</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>

        <span class="c1"># compute messages "m_ij" from  equation (3)</span>
        <span class="n">node_messages</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_message_function</span><span class="p">(</span><span class="n">node_embed</span><span class="p">[</span><span class="n">row</span><span class="p">],</span> <span class="n">node_embed</span><span class="p">[</span><span class="n">col</span><span class="p">],</span> <span class="n">dist</span><span class="p">)</span>

        <span class="c1"># message sum aggregation in equation (4)</span>
        <span class="n">aggr_node_messages</span> <span class="o">=</span> <span class="n">scatter</span><span class="p">(</span><span class="n">node_messages</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="s2">"sum"</span><span class="p">)</span>

        <span class="c1"># compute new node embeddings "h_i^{l+1}"</span>
        <span class="c1"># (implements rest of equation (4))</span>
        <span class="n">new_node_embed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">residual_proj</span><span class="p">(</span><span class="n">node_embed</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_update_mlp</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">node_embed</span><span class="p">,</span> <span class="n">aggr_node_messages</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">new_node_embed</span>


<span class="k">class</span> <span class="nc">EquivariantGNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">hidden_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">final_embedding_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">target_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">num_mp_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">final_embedding_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">final_embedding_size</span> <span class="o">=</span> <span class="n">hidden_channels</span>

        <span class="c1"># non-linear activation func.</span>
        <span class="c1"># usually configurable, here we just use Relu for simplicity</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">act</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>

        <span class="c1"># equation (1) "psi_0"</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f_initial_embed</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">)</span>

        <span class="c1"># create stack of message passing layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">message_passing_layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
        <span class="n">channels</span> <span class="o">=</span> <span class="p">[</span><span class="n">hidden_channels</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">num_mp_layers</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="n">final_embedding_size</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">d_in</span><span class="p">,</span> <span class="n">d_out</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">channels</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">channels</span><span class="p">[</span><span class="mi">1</span><span class="p">:]):</span>
            <span class="n">layer</span> <span class="o">=</span> <span class="n">EquivariantMPLayer</span><span class="p">(</span><span class="n">d_in</span><span class="p">,</span> <span class="n">d_out</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">act</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">message_passing_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span>

        <span class="c1"># modules required for readout of a graph-level</span>
        <span class="c1"># representation and graph-level property prediction</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">aggregation</span> <span class="o">=</span> <span class="n">SumAggregation</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f_predict</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">final_embedding_size</span><span class="p">,</span> <span class="n">final_embedding_size</span><span class="p">),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">act</span><span class="p">,</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">final_embedding_size</span><span class="p">,</span> <span class="n">target_size</span><span class="p">),</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">Data</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="c1"># theory, equation (1)</span>
        <span class="n">node_embed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_initial_embed</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">z</span><span class="p">)</span>
        <span class="c1"># message passing</span>
        <span class="c1"># theory, equation (3-4)</span>
        <span class="k">for</span> <span class="n">mp_layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">message_passing_layers</span><span class="p">:</span>
            <span class="c1"># NOTE here we use the complete edge index defined by the transform earlier on</span>
            <span class="c1"># to implement the sum over $j \neq i$ in equation (4)</span>
            <span class="n">node_embed</span> <span class="o">=</span> <span class="n">mp_layer</span><span class="p">(</span><span class="n">node_embed</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">pos</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">complete_edge_index</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">node_embed</span>

    <span class="k">def</span> <span class="nf">_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node_embed</span><span class="p">,</span> <span class="n">batch_index</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="n">aggr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">aggregation</span><span class="p">(</span><span class="n">node_embed</span><span class="p">,</span> <span class="n">batch_index</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_predict</span><span class="p">(</span><span class="n">aggr</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">Data</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="n">node_embed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_predict</span><span class="p">(</span><span class="n">node_embed</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">pred</span>
</pre></div>
</div>
</div>
</section>
<section id="Demo:-Our-EGNN-is-E(3)-invariant">
<h4 id="Demo:-Our-EGNN-is-E(3)-invariant">Demo: Our EGNN is <span class="math notranslate nohighlight">\(E(3)\)</span>-invariant<a class="headerlink" href="#Demo:-Our-EGNN-is-E(3)-invariant" title="Permalink to this heading">¶</a></h4>
<p>We can collect evidence that this model is indeed <span class="math notranslate nohighlight">\(\text{E}(n)\)</span>-invariant by repeating the experiment we conducted earlier.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">EquivariantGNN</span><span class="p">(</span><span class="n">hidden_channels</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">final_embedding_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_mp_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Some data points from qm9</span>
<span class="n">sample_data</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="mi">800</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>

<span class="c1"># apply E(3) transformation</span>
<span class="n">rotated_sample_data</span> <span class="o">=</span> <span class="n">sample_data</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
<span class="n">rotated_sample_data</span><span class="o">.</span><span class="n">pos</span> <span class="o">=</span> <span class="n">rotated_sample_data</span><span class="o">.</span><span class="n">pos</span> <span class="o">@</span> <span class="n">rotation_matrix_z</span><span class="p">(</span><span class="mi">120</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>

<span class="n">ax1</span> <span class="o">=</span> <span class="n">plot_model_input</span><span class="p">(</span><span class="n">sample_data</span><span class="p">,</span> <span class="n">fig</span><span class="p">,</span> <span class="mi">221</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"Sample input $(X, Z)$"</span><span class="p">)</span>

<span class="n">ax2</span> <span class="o">=</span> <span class="n">plot_model_input</span><span class="p">(</span><span class="n">rotated_sample_data</span><span class="p">,</span> <span class="n">fig</span><span class="p">,</span> <span class="mi">222</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"Rotated input $(X, g(Z))$"</span><span class="p">)</span>

<span class="n">ax3</span> <span class="o">=</span> <span class="n">plot_model_embedding</span><span class="p">(</span><span class="n">sample_data</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">encode</span><span class="p">,</span> <span class="n">fig</span><span class="p">,</span> <span class="mi">223</span><span class="p">)</span>
<span class="n">ax3</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"Model output for $(X, Z)$"</span><span class="p">)</span>

<span class="n">ax4</span> <span class="o">=</span> <span class="n">plot_model_embedding</span><span class="p">(</span><span class="n">rotated_sample_data</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">encode</span><span class="p">,</span> <span class="n">fig</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span>
<span class="n">ax4</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"Model output for $(X, g(Z))$"</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/tmp/ipykernel_51907/441942460.py:53: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.
  cmap = mpl.cm.get_cmap(cmap)
/tmp/ipykernel_51907/1099465595.py:21: UserWarning: Tight layout not applied. tight_layout cannot make axes width small enough to accommodate all axes decorations
  fig.tight_layout()
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/talktorials_T036_e3_equivariant_gnn_54_1.png" src="../_images/talktorials_T036_e3_equivariant_gnn_54_1.png"/>
</div>
</div>
<p>You can execute the above cells as often as you like, with whatever input you choose, the atom embeddings will always be unaffected by the rotation applied to the model input.</p>
</section>
</section>
<section id="Training-and-evaluation">
<h3 id="Training-and-evaluation">Training and evaluation<a class="headerlink" href="#Training-and-evaluation" title="Permalink to this heading">¶</a></h3>
<p>Now that we have set up our data and implemented two different models for point clouds, we can start implementing a training and evaluation pipeline.</p>
<p>We will follow the ubiquitous ML principle of also monitoring a validation loss in addition to the training loss. The validation loss acts as an estimate for how well the model generalizes and can be used for selecting a final model to be tested.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># We will be using mean absolute error</span>
<span class="c1"># as a metric for validation and testing</span>
<span class="k">def</span> <span class="nf">total_absolute_error</span><span class="p">(</span><span class="n">pred</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">target</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">batch_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Total absolute error, i.e. sums over batch dimension.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    pred : Tensor</span>
<span class="sd">        batch of model predictions</span>
<span class="sd">    target : Tensor</span>
<span class="sd">        batch of ground truth / target values</span>
<span class="sd">    batch_dim : int, optional</span>
<span class="sd">        dimension that indexes batch elements, by default 0</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Tensor</span>
<span class="sd">        total absolute error</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">pred</span> <span class="o">-</span> <span class="n">target</span><span class="p">)</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">batch_dim</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">run_epoch</span><span class="p">(</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
    <span class="n">loader</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span>
    <span class="n">criterion</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">],</span>
    <span class="n">pbar</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">optim</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">"""Run a single epoch.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    model : nn.Module</span>
<span class="sd">        the NN used for regression</span>
<span class="sd">    loader : DataLoader</span>
<span class="sd">        an iterable over data batches</span>
<span class="sd">    criterion : Callable[[Tensor, Tensor], Tensor]</span>
<span class="sd">        a criterion (loss) that is optimized</span>
<span class="sd">    pbar : Optional[Any], optional</span>
<span class="sd">        a tqdm progress bar, by default None</span>
<span class="sd">    optim : Optional[torch.optim.Optimizer], optional</span>
<span class="sd">        a optimizer that is optimizing the criterion, by default None</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span>
        <span class="n">data_batch</span><span class="p">:</span> <span class="n">Data</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">"""Perform a single train/val step on a data batch.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data_batch : Data</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Tuple[float, float]</span>
<span class="sd">            Loss (mean squared error) and validation critierion (absolute error).</span>
<span class="sd">        """</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">data_batch</span><span class="p">)</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">data_batch</span><span class="o">.</span><span class="n">y</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">optim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">optim</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optim</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">total_absolute_error</span><span class="p">(</span><span class="n">pred</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span> <span class="n">target</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>

    <span class="k">if</span> <span class="n">optim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="c1"># This enables pytorch autodiff s.t. we can compute gradients</span>
        <span class="n">model</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="c1"># disable autodiff: when evaluating we do not need to track gradients</span>
        <span class="n">model</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

    <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total_mae</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">:</span>
        <span class="n">loss</span><span class="p">,</span> <span class="n">mae</span> <span class="o">=</span> <span class="n">step</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span> <span class="o">*</span> <span class="n">data</span><span class="o">.</span><span class="n">num_graphs</span>
        <span class="n">total_mae</span> <span class="o">+=</span> <span class="n">mae</span>
        <span class="k">if</span> <span class="n">pbar</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">pbar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">),</span> <span class="n">total_mae</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span>
    <span class="n">data_module</span><span class="p">:</span> <span class="n">QM9DataModule</span><span class="p">,</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
    <span class="n">num_epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">30</span><span class="p">,</span>
    <span class="n">lr</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">3e-4</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span>
    <span class="n">weight_decay</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-8</span><span class="p">,</span>
    <span class="n">best_model_path</span><span class="p">:</span> <span class="n">Path</span> <span class="o">=</span> <span class="n">DATA</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="s2">"trained_model.pth"</span><span class="p">),</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">"""Takes data and model as input and runs training, collecting additional validation metrics</span>
<span class="sd">    while doing so.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data_module : QM9DataModule</span>
<span class="sd">        a data module as defined earlier</span>
<span class="sd">    model : nn.Module</span>
<span class="sd">        a gnn model</span>
<span class="sd">    num_epochs : int, optional</span>
<span class="sd">        number of epochs to train for, by default 30</span>
<span class="sd">    lr : float, optional</span>
<span class="sd">        "learning rate": optimizer SGD step size, by default 3e-4</span>
<span class="sd">    batch_size : int, optional</span>
<span class="sd">        number of examples used for one training step, by default 32</span>
<span class="sd">    weight_decay : float, optional</span>
<span class="sd">        L2 regularization parameter, by default 1e-8</span>
<span class="sd">    best_model_path : Path, optional</span>
<span class="sd">        path where the model weights with lowest val. error should be stored</span>
<span class="sd">        , by default DATA.joinpath("trained_model.pth")</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Dict[str, Any]</span>
<span class="sd">        a training result, ie statistics and info about the model</span>
<span class="sd">    """</span>
    <span class="c1"># create data loaders</span>
    <span class="n">train_loader</span> <span class="o">=</span> <span class="n">data_module</span><span class="o">.</span><span class="n">train_loader</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="n">val_loader</span> <span class="o">=</span> <span class="n">data_module</span><span class="o">.</span><span class="n">val_loader</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>

    <span class="c1"># setup optimizer and loss</span>
    <span class="n">optim</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">)</span>
    <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>

    <span class="c1"># keep track of the epoch with the best validation mae</span>
    <span class="c1"># st we can save the "best" model weights</span>
    <span class="n">best_val_mae</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">"inf"</span><span class="p">)</span>

    <span class="c1"># Statistics that will be plotted later on</span>
    <span class="c1"># and model info</span>
    <span class="n">result</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">"model"</span><span class="p">:</span> <span class="n">model</span><span class="p">,</span>
        <span class="s2">"path_to_best_model"</span><span class="p">:</span> <span class="n">best_model_path</span><span class="p">,</span>
        <span class="s2">"train_loss"</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s2">"nan"</span><span class="p">)),</span>
        <span class="s2">"val_loss"</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s2">"nan"</span><span class="p">)),</span>
        <span class="s2">"train_mae"</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s2">"nan"</span><span class="p">)),</span>
        <span class="s2">"val_mae"</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s2">"nan"</span><span class="p">)),</span>
    <span class="p">}</span>

    <span class="c1"># Auxiliary functions for updating and reporting</span>
    <span class="c1"># Training progress statistics</span>
    <span class="k">def</span> <span class="nf">update_statistics</span><span class="p">(</span><span class="n">i_epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">result</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="n">i_epoch</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>

    <span class="k">def</span> <span class="nf">desc</span><span class="p">(</span><span class="n">i_epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="s2">" | "</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
            <span class="p">[</span><span class="sa">f</span><span class="s2">"Epoch </span><span class="si">{</span><span class="n">i_epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">:</span><span class="s2">3d</span><span class="si">}</span><span class="s2"> / </span><span class="si">{</span><span class="n">num_epochs</span><span class="si">}</span><span class="s2">"</span><span class="p">]</span>
            <span class="o">+</span> <span class="p">[</span>
                <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">value</span><span class="p">[</span><span class="n">i_epoch</span><span class="p">]</span><span class="si">:</span><span class="s2">8.2f</span><span class="si">}</span><span class="s2">"</span>
                <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">result</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span>
            <span class="p">]</span>
        <span class="p">)</span>

    <span class="c1"># main training loop</span>
    <span class="k">for</span> <span class="n">i_epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">):</span>
        <span class="n">progress_bar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_loader</span><span class="p">))</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># tqdm for reporting progress</span>
            <span class="n">progress_bar</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span><span class="n">desc</span><span class="p">(</span><span class="n">i_epoch</span><span class="p">))</span>

            <span class="c1"># training epoch</span>
            <span class="n">train_loss</span><span class="p">,</span> <span class="n">train_mae</span> <span class="o">=</span> <span class="n">run_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">progress_bar</span><span class="p">,</span> <span class="n">optim</span><span class="p">)</span>
            <span class="c1"># validation epoch</span>
            <span class="n">val_loss</span><span class="p">,</span> <span class="n">val_mae</span> <span class="o">=</span> <span class="n">run_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">progress_bar</span><span class="p">)</span>

            <span class="n">update_statistics</span><span class="p">(</span>
                <span class="n">i_epoch</span><span class="p">,</span>
                <span class="n">train_loss</span><span class="o">=</span><span class="n">train_loss</span><span class="p">,</span>
                <span class="n">val_loss</span><span class="o">=</span><span class="n">val_loss</span><span class="p">,</span>
                <span class="n">train_mae</span><span class="o">=</span><span class="n">train_mae</span><span class="p">,</span>
                <span class="n">val_mae</span><span class="o">=</span><span class="n">val_mae</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">progress_bar</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span><span class="n">desc</span><span class="p">(</span><span class="n">i_epoch</span><span class="p">))</span>

            <span class="k">if</span> <span class="n">val_mae</span> <span class="o">&lt;</span> <span class="n">best_val_mae</span><span class="p">:</span>
                <span class="n">best_val_mae</span> <span class="o">=</span> <span class="n">val_mae</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">best_model_path</span><span class="p">)</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="n">progress_bar</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">result</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">test_model</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">data_module</span><span class="p">:</span> <span class="n">QM9DataModule</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Test a model.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    model : nn.Module</span>
<span class="sd">        a trained model</span>
<span class="sd">    data_module : QM9DataModule</span>
<span class="sd">        a data module as defined earlier</span>
<span class="sd">        from which we'll get the test data</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    _Tuple[float, Tensor, Tensor]</span>
<span class="sd">        Test MAE, and model predictions &amp; targets for further processing</span>
<span class="sd">    """</span>
    <span class="n">test_mae</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">preds</span><span class="p">,</span> <span class="n">targets</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="n">loader</span> <span class="o">=</span> <span class="n">data_module</span><span class="o">.</span><span class="n">test_loader</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">:</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">y</span>
        <span class="n">preds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>
        <span class="n">targets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>
        <span class="n">test_mae</span> <span class="o">+=</span> <span class="n">total_absolute_error</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="n">test_mae</span> <span class="o">=</span> <span class="n">test_mae</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_module</span><span class="o">.</span><span class="n">test_split</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">test_mae</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">targets</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<section id="Training-the-EGNN">
<h4 id="Training-the-EGNN">Training the EGNN<a class="headerlink" href="#Training-the-EGNN" title="Permalink to this heading">¶</a></h4>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">EquivariantGNN</span><span class="p">(</span><span class="n">hidden_channels</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">num_mp_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">egnn_train_result</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span>
    <span class="n">data_module</span><span class="p">,</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">num_epochs</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span>
    <span class="n">lr</span><span class="o">=</span><span class="mf">2e-4</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
    <span class="n">weight_decay</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">,</span>
    <span class="n">best_model_path</span><span class="o">=</span><span class="n">DATA</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="s2">"trained_egnn.pth"</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
~/.miniconda3/envs/teachopencadd/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
Epoch   1 / 25 | train_loss: 83816.98 | val_loss:  8249.58 | train_mae:   177.73 | val_mae:    62.58: 100%|█████████████████████████████████████████████████| 614/614 [00:28&lt;00:00, 21.82it/s]
Epoch   2 / 25 | train_loss:  5193.82 | val_loss:  2884.07 | train_mae:    51.31 | val_mae:    34.33: 100%|█████████████████████████████████████████████████| 614/614 [00:21&lt;00:00, 28.63it/s]
Epoch   3 / 25 | train_loss:  1847.79 | val_loss:   932.89 | train_mae:    29.56 | val_mae:    20.27: 100%|█████████████████████████████████████████████████| 614/614 [00:19&lt;00:00, 31.40it/s]
Epoch   4 / 25 | train_loss:   853.45 | val_loss:   786.19 | train_mae:    20.28 | val_mae:    21.96: 100%|█████████████████████████████████████████████████| 614/614 [00:18&lt;00:00, 32.92it/s]
Epoch   5 / 25 | train_loss:   619.10 | val_loss:   389.76 | train_mae:    17.42 | val_mae:    13.32: 100%|█████████████████████████████████████████████████| 614/614 [00:18&lt;00:00, 32.35it/s]
Epoch   6 / 25 | train_loss:   479.23 | val_loss:   343.42 | train_mae:    15.32 | val_mae:    12.68: 100%|█████████████████████████████████████████████████| 614/614 [00:19&lt;00:00, 31.53it/s]
Epoch   7 / 25 | train_loss:   383.88 | val_loss:   285.21 | train_mae:    13.70 | val_mae:    11.90: 100%|█████████████████████████████████████████████████| 614/614 [00:21&lt;00:00, 29.10it/s]
Epoch   8 / 25 | train_loss:   306.98 | val_loss:   201.01 | train_mae:    12.24 | val_mae:     9.67: 100%|█████████████████████████████████████████████████| 614/614 [00:19&lt;00:00, 30.92it/s]
Epoch   9 / 25 | train_loss:   259.13 | val_loss:   387.28 | train_mae:    11.30 | val_mae:    16.76: 100%|█████████████████████████████████████████████████| 614/614 [00:19&lt;00:00, 30.84it/s]
Epoch  10 / 25 | train_loss:   265.28 | val_loss:   231.35 | train_mae:    11.62 | val_mae:    11.55: 100%|█████████████████████████████████████████████████| 614/614 [00:18&lt;00:00, 33.07it/s]
Epoch  11 / 25 | train_loss:   187.75 | val_loss:   148.88 | train_mae:     9.50 | val_mae:     8.89: 100%|█████████████████████████████████████████████████| 614/614 [00:18&lt;00:00, 32.69it/s]
Epoch  12 / 25 | train_loss:   168.02 | val_loss:   303.56 | train_mae:     9.35 | val_mae:    15.35: 100%|█████████████████████████████████████████████████| 614/614 [00:18&lt;00:00, 32.65it/s]
Epoch  13 / 25 | train_loss:   153.95 | val_loss:    86.36 | train_mae:     9.01 | val_mae:     6.31: 100%|█████████████████████████████████████████████████| 614/614 [00:20&lt;00:00, 30.39it/s]
Epoch  14 / 25 | train_loss:   136.87 | val_loss:    73.61 | train_mae:     8.50 | val_mae:     5.95: 100%|█████████████████████████████████████████████████| 614/614 [00:23&lt;00:00, 25.83it/s]
Epoch  15 / 25 | train_loss:   111.18 | val_loss:   144.24 | train_mae:     7.67 | val_mae:    10.03: 100%|█████████████████████████████████████████████████| 614/614 [00:18&lt;00:00, 32.98it/s]
Epoch  16 / 25 | train_loss:   110.45 | val_loss:   127.40 | train_mae:     7.69 | val_mae:     9.73: 100%|█████████████████████████████████████████████████| 614/614 [00:20&lt;00:00, 30.23it/s]
Epoch  17 / 25 | train_loss:    88.18 | val_loss:    87.97 | train_mae:     6.83 | val_mae:     7.15: 100%|█████████████████████████████████████████████████| 614/614 [00:21&lt;00:00, 28.76it/s]
Epoch  18 / 25 | train_loss:    96.38 | val_loss:    69.41 | train_mae:     7.21 | val_mae:     6.59: 100%|█████████████████████████████████████████████████| 614/614 [00:22&lt;00:00, 27.20it/s]
Epoch  19 / 25 | train_loss:    66.19 | val_loss:   213.51 | train_mae:     5.91 | val_mae:    13.43: 100%|█████████████████████████████████████████████████| 614/614 [00:21&lt;00:00, 28.50it/s]
Epoch  20 / 25 | train_loss:    97.42 | val_loss:    30.31 | train_mae:     6.86 | val_mae:     3.56: 100%|█████████████████████████████████████████████████| 614/614 [00:21&lt;00:00, 29.20it/s]
Epoch  21 / 25 | train_loss:    66.18 | val_loss:    31.33 | train_mae:     5.98 | val_mae:     3.84: 100%|█████████████████████████████████████████████████| 614/614 [00:18&lt;00:00, 32.92it/s]
Epoch  22 / 25 | train_loss:    64.28 | val_loss:    42.74 | train_mae:     5.82 | val_mae:     4.67: 100%|█████████████████████████████████████████████████| 614/614 [00:21&lt;00:00, 28.31it/s]
Epoch  23 / 25 | train_loss:    65.13 | val_loss:   102.03 | train_mae:     5.96 | val_mae:     8.89: 100%|█████████████████████████████████████████████████| 614/614 [00:18&lt;00:00, 32.82it/s]
Epoch  24 / 25 | train_loss:    71.31 | val_loss:   142.06 | train_mae:     6.10 | val_mae:     8.94: 100%|█████████████████████████████████████████████████| 614/614 [00:18&lt;00:00, 33.01it/s]
Epoch  25 / 25 | train_loss:    63.18 | val_loss:    28.93 | train_mae:     5.71 | val_mae:     3.54: 100%|█████████████████████████████████████████████████| 614/614 [00:18&lt;00:00, 32.71it/s]
</pre></div></div>
</div>
</section>
<section id="Training-the-plain-GNN">
<h4 id="Training-the-plain-GNN">Training the plain GNN<a class="headerlink" href="#Training-the-plain-GNN" title="Permalink to this heading">¶</a></h4>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gcn_baseline</span> <span class="o">=</span> <span class="n">NaiveEuclideanGNN</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="n">gcn_train_result</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span>
    <span class="n">data_module</span><span class="p">,</span>
    <span class="n">gcn_baseline</span><span class="p">,</span>
    <span class="n">num_epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">lr</span><span class="o">=</span><span class="mf">3e-4</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
    <span class="n">best_model_path</span><span class="o">=</span><span class="n">DATA</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="s2">"trained_gnn.pth"</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Epoch   1 / 100 | train_loss: 131605.16 | val_loss: 51881.71 | train_mae:   257.84 | val_mae:   178.73: 100%|███████████████████████████████████████████████| 614/614 [00:10&lt;00:00, 59.30it/s]
Epoch   2 / 100 | train_loss: 46252.38 | val_loss: 33482.20 | train_mae:   159.96 | val_mae:   139.05: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 86.94it/s]
Epoch   3 / 100 | train_loss: 31016.87 | val_loss: 25729.41 | train_mae:   131.66 | val_mae:   118.91: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 81.91it/s]
Epoch   4 / 100 | train_loss: 19575.64 | val_loss: 16162.15 | train_mae:   104.25 | val_mae:    95.53: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 82.16it/s]
Epoch   5 / 100 | train_loss: 13219.30 | val_loss: 18588.67 | train_mae:    85.73 | val_mae:   111.78: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 78.85it/s]
Epoch   6 / 100 | train_loss: 10594.13 | val_loss:  9926.80 | train_mae:    76.39 | val_mae:    69.72: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 86.72it/s]
Epoch   7 / 100 | train_loss:  8526.29 | val_loss:  9002.18 | train_mae:    67.99 | val_mae:    67.95: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 86.48it/s]
Epoch   8 / 100 | train_loss:  7094.07 | val_loss:  6584.26 | train_mae:    62.25 | val_mae:    56.78: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 86.69it/s]
Epoch   9 / 100 | train_loss:  6621.97 | val_loss:  6924.00 | train_mae:    59.52 | val_mae:    58.06: 100%|████████████████████████████████████████████████| 614/614 [00:06&lt;00:00, 87.96it/s]
Epoch  10 / 100 | train_loss:  6078.34 | val_loss:  6341.89 | train_mae:    56.62 | val_mae:    56.60: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 86.94it/s]
Epoch  11 / 100 | train_loss:  5703.69 | val_loss:  6478.72 | train_mae:    55.66 | val_mae:    58.99: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 85.74it/s]
Epoch  12 / 100 | train_loss:  5338.27 | val_loss:  5886.17 | train_mae:    53.40 | val_mae:    54.12: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 84.17it/s]
Epoch  13 / 100 | train_loss:  5155.95 | val_loss:  5749.83 | train_mae:    52.08 | val_mae:    52.79: 100%|████████████████████████████████████████████████| 614/614 [00:06&lt;00:00, 87.90it/s]
Epoch  14 / 100 | train_loss:  4964.06 | val_loss:  5171.14 | train_mae:    51.32 | val_mae:    49.19: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 85.07it/s]
Epoch  15 / 100 | train_loss:  4871.12 | val_loss:  5170.29 | train_mae:    50.80 | val_mae:    49.65: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 86.82it/s]
Epoch  16 / 100 | train_loss:  4644.91 | val_loss:  4882.15 | train_mae:    49.54 | val_mae:    46.48: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 85.09it/s]
Epoch  17 / 100 | train_loss:  4630.13 | val_loss:  6608.02 | train_mae:    49.50 | val_mae:    58.90: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 81.44it/s]
Epoch  18 / 100 | train_loss:  4616.51 | val_loss:  5037.78 | train_mae:    49.50 | val_mae:    49.18: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 80.24it/s]
Epoch  19 / 100 | train_loss:  4216.14 | val_loss:  5161.73 | train_mae:    46.83 | val_mae:    47.26: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 77.75it/s]
Epoch  20 / 100 | train_loss:  4141.20 | val_loss:  4744.50 | train_mae:    46.76 | val_mae:    46.50: 100%|████████████████████████████████████████████████| 614/614 [00:08&lt;00:00, 76.75it/s]
Epoch  21 / 100 | train_loss:  4027.40 | val_loss:  4649.81 | train_mae:    46.30 | val_mae:    45.15: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 81.51it/s]
Epoch  22 / 100 | train_loss:  3948.61 | val_loss:  4409.36 | train_mae:    45.76 | val_mae:    45.78: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 81.78it/s]
Epoch  23 / 100 | train_loss:  3980.70 | val_loss:  4948.89 | train_mae:    45.73 | val_mae:    48.64: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 87.25it/s]
Epoch  24 / 100 | train_loss:  3621.07 | val_loss:  4880.79 | train_mae:    43.77 | val_mae:    49.11: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 86.39it/s]
Epoch  25 / 100 | train_loss:  3692.66 | val_loss:  6213.45 | train_mae:    44.01 | val_mae:    55.11: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 87.52it/s]
Epoch  26 / 100 | train_loss:  3850.76 | val_loss:  4153.96 | train_mae:    45.27 | val_mae:    44.38: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 86.56it/s]
Epoch  27 / 100 | train_loss:  3442.45 | val_loss:  4037.86 | train_mae:    42.52 | val_mae:    42.73: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 86.44it/s]
Epoch  28 / 100 | train_loss:  3333.53 | val_loss:  4577.04 | train_mae:    41.92 | val_mae:    47.31: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 85.67it/s]
Epoch  29 / 100 | train_loss:  3418.91 | val_loss:  3798.06 | train_mae:    42.22 | val_mae:    40.75: 100%|████████████████████████████████████████████████| 614/614 [00:06&lt;00:00, 88.26it/s]
Epoch  30 / 100 | train_loss:  3373.68 | val_loss:  4033.93 | train_mae:    42.03 | val_mae:    41.66: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 87.06it/s]
Epoch  31 / 100 | train_loss:  3111.80 | val_loss:  3682.38 | train_mae:    40.34 | val_mae:    40.78: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 87.05it/s]
Epoch  32 / 100 | train_loss:  3117.61 | val_loss:  3806.91 | train_mae:    40.66 | val_mae:    41.78: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 87.66it/s]
Epoch  33 / 100 | train_loss:  3206.69 | val_loss:  3581.51 | train_mae:    40.87 | val_mae:    40.26: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 86.08it/s]
Epoch  34 / 100 | train_loss:  3079.73 | val_loss:  4547.30 | train_mae:    40.19 | val_mae:    45.41: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 79.78it/s]
Epoch  35 / 100 | train_loss:  3149.01 | val_loss:  4522.56 | train_mae:    40.80 | val_mae:    45.55: 100%|████████████████████████████████████████████████| 614/614 [00:06&lt;00:00, 90.56it/s]
Epoch  36 / 100 | train_loss:  2918.20 | val_loss:  3964.84 | train_mae:    39.13 | val_mae:    41.33: 100%|████████████████████████████████████████████████| 614/614 [00:06&lt;00:00, 95.45it/s]
Epoch  37 / 100 | train_loss:  2908.17 | val_loss:  4062.00 | train_mae:    39.27 | val_mae:    42.20: 100%|████████████████████████████████████████████████| 614/614 [00:06&lt;00:00, 92.70it/s]
Epoch  38 / 100 | train_loss:  2858.89 | val_loss:  3632.95 | train_mae:    39.15 | val_mae:    39.16: 100%|████████████████████████████████████████████████| 614/614 [00:06&lt;00:00, 93.83it/s]
Epoch  39 / 100 | train_loss:  2911.77 | val_loss:  4292.41 | train_mae:    39.19 | val_mae:    45.72: 100%|████████████████████████████████████████████████| 614/614 [00:06&lt;00:00, 91.97it/s]
Epoch  40 / 100 | train_loss:  2774.28 | val_loss:  4351.61 | train_mae:    38.52 | val_mae:    44.17: 100%|████████████████████████████████████████████████| 614/614 [00:08&lt;00:00, 74.30it/s]
Epoch  41 / 100 | train_loss:  2828.55 | val_loss:  3983.95 | train_mae:    38.97 | val_mae:    43.67: 100%|████████████████████████████████████████████████| 614/614 [00:08&lt;00:00, 71.27it/s]
Epoch  42 / 100 | train_loss:  2639.83 | val_loss:  3555.43 | train_mae:    37.39 | val_mae:    39.24: 100%|████████████████████████████████████████████████| 614/614 [00:06&lt;00:00, 89.57it/s]
Epoch  43 / 100 | train_loss:  2802.29 | val_loss:  3784.69 | train_mae:    38.28 | val_mae:    40.87: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 84.90it/s]
Epoch  44 / 100 | train_loss:  2669.42 | val_loss:  4253.03 | train_mae:    37.75 | val_mae:    42.04: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 80.92it/s]
Epoch  45 / 100 | train_loss:  2543.59 | val_loss:  3882.21 | train_mae:    36.53 | val_mae:    41.58: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 84.11it/s]
Epoch  46 / 100 | train_loss:  2563.37 | val_loss:  3912.68 | train_mae:    36.96 | val_mae:    41.34: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 85.72it/s]
Epoch  47 / 100 | train_loss:  2559.09 | val_loss:  5493.43 | train_mae:    37.02 | val_mae:    51.46: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 85.71it/s]
Epoch  48 / 100 | train_loss:  2576.10 | val_loss:  4768.31 | train_mae:    36.85 | val_mae:    52.41: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 86.25it/s]
Epoch  49 / 100 | train_loss:  2398.73 | val_loss:  3751.79 | train_mae:    35.63 | val_mae:    38.73: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 86.18it/s]
Epoch  50 / 100 | train_loss:  2565.22 | val_loss:  3555.04 | train_mae:    37.00 | val_mae:    37.67: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 86.84it/s]
Epoch  51 / 100 | train_loss:  2360.89 | val_loss:  3545.71 | train_mae:    35.47 | val_mae:    40.19: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 87.31it/s]
Epoch  52 / 100 | train_loss:  2467.34 | val_loss:  3806.81 | train_mae:    36.17 | val_mae:    40.76: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 87.50it/s]
Epoch  53 / 100 | train_loss:  2312.26 | val_loss:  3497.13 | train_mae:    35.16 | val_mae:    37.88: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 86.50it/s]
Epoch  54 / 100 | train_loss:  2167.41 | val_loss:  3487.33 | train_mae:    34.01 | val_mae:    36.67: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 86.55it/s]
Epoch  55 / 100 | train_loss:  2185.56 | val_loss:  3963.23 | train_mae:    34.25 | val_mae:    40.11: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 77.66it/s]
Epoch  56 / 100 | train_loss:  2280.32 | val_loss:  3320.05 | train_mae:    34.80 | val_mae:    36.47: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 85.87it/s]
Epoch  57 / 100 | train_loss:  2211.96 | val_loss:  3721.73 | train_mae:    34.26 | val_mae:    39.31: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 87.31it/s]
Epoch  58 / 100 | train_loss:  2284.40 | val_loss:  3462.30 | train_mae:    34.87 | val_mae:    38.11: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 85.90it/s]
Epoch  59 / 100 | train_loss:  2304.63 | val_loss:  3297.33 | train_mae:    35.03 | val_mae:    36.64: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 87.13it/s]
Epoch  60 / 100 | train_loss:  2117.74 | val_loss:  3451.63 | train_mae:    33.53 | val_mae:    38.31: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 85.60it/s]
Epoch  61 / 100 | train_loss:  2247.47 | val_loss:  3426.57 | train_mae:    34.57 | val_mae:    39.07: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 87.00it/s]
Epoch  62 / 100 | train_loss:  2037.65 | val_loss:  3057.25 | train_mae:    32.89 | val_mae:    36.22: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 86.02it/s]
Epoch  63 / 100 | train_loss:  2076.61 | val_loss:  3299.59 | train_mae:    33.09 | val_mae:    35.54: 100%|████████████████████████████████████████████████| 614/614 [00:06&lt;00:00, 88.46it/s]
Epoch  64 / 100 | train_loss:  2004.54 | val_loss:  3806.01 | train_mae:    32.72 | val_mae:    41.34: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 86.80it/s]
Epoch  65 / 100 | train_loss:  1974.01 | val_loss:  3369.84 | train_mae:    32.42 | val_mae:    35.64: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 83.84it/s]
Epoch  66 / 100 | train_loss:  1968.44 | val_loss:  3482.79 | train_mae:    32.30 | val_mae:    38.24: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 85.11it/s]
Epoch  67 / 100 | train_loss:  1977.37 | val_loss:  3171.34 | train_mae:    32.50 | val_mae:    36.01: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 86.51it/s]
Epoch  68 / 100 | train_loss:  1863.63 | val_loss:  3157.46 | train_mae:    31.64 | val_mae:    34.47: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 86.52it/s]
Epoch  69 / 100 | train_loss:  1961.02 | val_loss:  3296.61 | train_mae:    32.31 | val_mae:    37.72: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 81.34it/s]
Epoch  70 / 100 | train_loss:  1943.04 | val_loss:  3274.01 | train_mae:    32.25 | val_mae:    34.72: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 84.12it/s]
Epoch  71 / 100 | train_loss:  1889.30 | val_loss:  3842.83 | train_mae:    31.79 | val_mae:    40.47: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 81.92it/s]
Epoch  72 / 100 | train_loss:  1896.79 | val_loss:  4150.15 | train_mae:    31.78 | val_mae:    43.21: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 82.86it/s]
Epoch  73 / 100 | train_loss:  1860.80 | val_loss:  3174.58 | train_mae:    31.54 | val_mae:    35.24: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 87.59it/s]
Epoch  74 / 100 | train_loss:  1870.97 | val_loss:  3089.24 | train_mae:    31.62 | val_mae:    36.22: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 77.78it/s]
Epoch  75 / 100 | train_loss:  1869.31 | val_loss:  3397.72 | train_mae:    31.83 | val_mae:    37.43: 100%|████████████████████████████████████████████████| 614/614 [00:08&lt;00:00, 71.10it/s]
Epoch  76 / 100 | train_loss:  1723.28 | val_loss:  3294.50 | train_mae:    30.57 | val_mae:    34.38: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 82.95it/s]
Epoch  77 / 100 | train_loss:  2041.00 | val_loss:  3031.84 | train_mae:    32.94 | val_mae:    34.34: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 76.83it/s]
Epoch  78 / 100 | train_loss:  1670.29 | val_loss:  3470.53 | train_mae:    29.81 | val_mae:    38.44: 100%|████████████████████████████████████████████████| 614/614 [00:08&lt;00:00, 74.45it/s]
Epoch  79 / 100 | train_loss:  1795.03 | val_loss:  3402.04 | train_mae:    31.12 | val_mae:    38.37: 100%|████████████████████████████████████████████████| 614/614 [00:09&lt;00:00, 65.54it/s]
Epoch  80 / 100 | train_loss:  1769.94 | val_loss:  3149.87 | train_mae:    30.62 | val_mae:    33.53: 100%|████████████████████████████████████████████████| 614/614 [00:08&lt;00:00, 74.66it/s]
Epoch  81 / 100 | train_loss:  1682.90 | val_loss:  3412.26 | train_mae:    30.09 | val_mae:    38.59: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 80.33it/s]
Epoch  82 / 100 | train_loss:  1737.01 | val_loss:  3396.11 | train_mae:    30.41 | val_mae:    35.16: 100%|████████████████████████████████████████████████| 614/614 [00:08&lt;00:00, 69.65it/s]
Epoch  83 / 100 | train_loss:  1967.99 | val_loss:  2990.12 | train_mae:    32.48 | val_mae:    33.36: 100%|████████████████████████████████████████████████| 614/614 [00:08&lt;00:00, 74.43it/s]
Epoch  84 / 100 | train_loss:  1722.19 | val_loss:  3358.17 | train_mae:    30.33 | val_mae:    35.79: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 77.35it/s]
Epoch  85 / 100 | train_loss:  1633.18 | val_loss:  3178.61 | train_mae:    29.64 | val_mae:    34.94: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 83.83it/s]
Epoch  86 / 100 | train_loss:  1691.06 | val_loss:  3589.25 | train_mae:    30.34 | val_mae:    39.16: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 80.62it/s]
Epoch  87 / 100 | train_loss:  1573.87 | val_loss:  3321.35 | train_mae:    29.09 | val_mae:    34.73: 100%|████████████████████████████████████████████████| 614/614 [00:08&lt;00:00, 70.68it/s]
Epoch  88 / 100 | train_loss:  1624.47 | val_loss:  3328.78 | train_mae:    29.65 | val_mae:    36.73: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 80.53it/s]
Epoch  89 / 100 | train_loss:  1566.87 | val_loss:  2961.29 | train_mae:    28.97 | val_mae:    34.25: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 83.01it/s]
Epoch  90 / 100 | train_loss:  1622.22 | val_loss:  3082.79 | train_mae:    29.63 | val_mae:    35.45: 100%|████████████████████████████████████████████████| 614/614 [00:08&lt;00:00, 68.98it/s]
Epoch  91 / 100 | train_loss:  1658.47 | val_loss:  2969.16 | train_mae:    30.08 | val_mae:    33.32: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 79.57it/s]
Epoch  92 / 100 | train_loss:  1495.98 | val_loss:  3389.66 | train_mae:    28.39 | val_mae:    34.39: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 77.54it/s]
Epoch  93 / 100 | train_loss:  1512.13 | val_loss:  3102.99 | train_mae:    28.54 | val_mae:    34.93: 100%|████████████████████████████████████████████████| 614/614 [00:08&lt;00:00, 73.15it/s]
Epoch  94 / 100 | train_loss:  1489.28 | val_loss:  3190.44 | train_mae:    28.52 | val_mae:    35.37: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 85.53it/s]
Epoch  95 / 100 | train_loss:  1651.04 | val_loss:  2940.62 | train_mae:    29.94 | val_mae:    32.10: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 86.13it/s]
Epoch  96 / 100 | train_loss:  1529.36 | val_loss:  3137.99 | train_mae:    28.90 | val_mae:    34.13: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 86.59it/s]
Epoch  97 / 100 | train_loss:  1531.24 | val_loss:  3489.23 | train_mae:    28.92 | val_mae:    38.00: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 87.50it/s]
Epoch  98 / 100 | train_loss:  1580.89 | val_loss:  2815.52 | train_mae:    29.14 | val_mae:    32.56: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 78.90it/s]
Epoch  99 / 100 | train_loss:  1518.98 | val_loss:  3225.39 | train_mae:    28.69 | val_mae:    32.25: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 85.77it/s]
Epoch 100 / 100 | train_loss:  1555.37 | val_loss:  3180.20 | train_mae:    29.11 | val_mae:    35.67: 100%|████████████████████████████████████████████████| 614/614 [00:07&lt;00:00, 86.09it/s]
</pre></div></div>
</div>
</section>
<section id="Comparative-evaluation">
<h4 id="Comparative-evaluation">Comparative evaluation<a class="headerlink" href="#Comparative-evaluation" title="Permalink to this heading">¶</a></h4>
<p>Let us now compare the trained EGNN and GNN baseline model. First note that in terms of capacity (measured by the number of trainable parameters) the models are very similar. But be aware that the comparison is still not completely fair, because</p>
<ul class="simple">
<li><p>the EGNN is a <em>message-passing</em> neural network while the baseline GNN is a type of <em>graph convolutional</em> neural network</p></li>
<li><p>the EGNN is run on complete graphs, whereas the baseline GNN uses the bond adjacency info, which could also be a disadvantage</p></li>
</ul>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gcn_num_params</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">gcn_train_result</span><span class="p">[</span><span class="s2">"model"</span><span class="p">]</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
<span class="n">egnn_num_params</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">egnn_train_result</span><span class="p">[</span><span class="s2">"model"</span><span class="p">]</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>

<span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="p">{</span><span class="s2">"GCN"</span><span class="p">:</span> <span class="n">gcn_num_params</span><span class="p">,</span> <span class="s2">"EGNN"</span><span class="p">:</span> <span class="n">egnn_num_params</span><span class="p">}</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2"> has </span><span class="si">{</span><span class="n">value</span><span class="si">}</span><span class="s2"> parameters"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
GCN has 52417 parameters
EGNN has 51969 parameters
</pre></div></div>
</div>
<p>Plotting the loss and validation MAE for each epoch, we can observe that the EGNN training progresses <em>much</em> faster and yields <em>much</em> better results, even though it is trained for a smaller number of epochs (note that loss and MAE are in log-scale).</p>
<p>Surprisingly the validation loss/MAE for the EGNN is sometimes <em>lower</em> than the train loss/MAE. This might be explained by the fact that the data split is <em>very</em> homogenous, and the validation data contains fewer outliers than the train data (see box plots from the section on distribution of regression target across splits).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">loss_ax</span><span class="p">,</span> <span class="n">mae_ax</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

<span class="n">loss_ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"Loss (MSE)"</span><span class="p">)</span>
<span class="n">mae_ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"MAE"</span><span class="p">)</span>
<span class="n">loss_ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">"Epoch"</span><span class="p">)</span>
<span class="n">mae_ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">"Epoch"</span><span class="p">)</span>

<span class="k">for</span> <span class="n">metric</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">"train_loss"</span><span class="p">,</span> <span class="s2">"val_loss"</span><span class="p">,</span> <span class="s2">"train_mae"</span><span class="p">,</span> <span class="s2">"val_mae"</span><span class="p">]:</span>
    <span class="n">split</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">"_"</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">loss_ax</span> <span class="k">if</span> <span class="s2">"loss"</span> <span class="ow">in</span> <span class="n">metric</span> <span class="k">else</span> <span class="n">mae_ax</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">egnn_train_result</span><span class="p">[</span><span class="n">metric</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">"EGNN </span><span class="si">{</span><span class="n">split</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">gcn_train_result</span><span class="p">[</span><span class="n">metric</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">"GNN </span><span class="si">{</span><span class="n">split</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="n">mae_ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">mae_ax</span><span class="o">.</span><span class="n">set_yscale</span><span class="p">(</span><span class="s2">"log"</span><span class="p">)</span>
<span class="n">loss_ax</span><span class="o">.</span><span class="n">set_yscale</span><span class="p">(</span><span class="s2">"log"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/talktorials_T036_e3_equivariant_gnn_67_0.png" src="../_images/talktorials_T036_e3_equivariant_gnn_67_0.png"/>
</div>
</div>
<p>This performance improvement can also be observed in the held-out test data. For testing, we select the best model as the model that had the lowest validation MAE each.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[28]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gcn_model</span> <span class="o">=</span> <span class="n">gcn_train_result</span><span class="p">[</span><span class="s2">"model"</span><span class="p">]</span>
<span class="n">gcn_model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">gcn_train_result</span><span class="p">[</span><span class="s2">"path_to_best_model"</span><span class="p">]))</span>
<span class="n">gcn_test_mae</span><span class="p">,</span> <span class="n">gcn_preds</span><span class="p">,</span> <span class="n">gcn_targets</span> <span class="o">=</span> <span class="n">test_model</span><span class="p">(</span><span class="n">gcn_model</span><span class="p">,</span> <span class="n">data_module</span><span class="p">)</span>

<span class="n">egnn_model</span> <span class="o">=</span> <span class="n">egnn_train_result</span><span class="p">[</span><span class="s2">"model"</span><span class="p">]</span>
<span class="n">egnn_model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">egnn_train_result</span><span class="p">[</span><span class="s2">"path_to_best_model"</span><span class="p">]))</span>
<span class="n">egnn_test_mae</span><span class="p">,</span> <span class="n">egnn_preds</span><span class="p">,</span> <span class="n">egnn_targets</span> <span class="o">=</span> <span class="n">test_model</span><span class="p">(</span><span class="n">egnn_model</span><span class="p">,</span> <span class="n">data_module</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"EGNN test MAE: </span><span class="si">{</span><span class="n">egnn_test_mae</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"GNN test MAE: </span><span class="si">{</span><span class="n">gcn_test_mae</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
EGNN test MAE: 3.4511184202421696
GNN test MAE: 31.881833081726633
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[29]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">gcn_targets</span><span class="p">,</span> <span class="n">gcn_targets</span><span class="p">,</span> <span class="s2">"--"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">"grey"</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">gcn_targets</span><span class="p">,</span> <span class="n">gcn_preds</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">"GNN"</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">egnn_targets</span><span class="p">,</span> <span class="n">egnn_preds</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">"EGNN"</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">"Model prediction"</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">"Ground truth $\langle R^2 </span><span class="se">\\</span><span class="s2">rangle$"</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"Test performance"</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[29]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;matplotlib.legend.Legend at 0x7f663bf0f700&gt;
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/talktorials_T036_e3_equivariant_gnn_70_1.png" src="../_images/talktorials_T036_e3_equivariant_gnn_70_1.png"/>
</div>
</div>
<p>These findings support our initial hypothesis that <span class="math notranslate nohighlight">\(\text{E}(3)\)</span>-invariant models lead to faster learning and improved generalization performance.</p>
</section>
</section>
</section>
<section id="Discussion">
<h2 id="Discussion">Discussion<a class="headerlink" href="#Discussion" title="Permalink to this heading">¶</a></h2>
<section id="Summary">
<h3 id="Summary">Summary<a class="headerlink" href="#Summary" title="Permalink to this heading">¶</a></h3>
<p>You have now seen, theoretically and practically, why we need <span class="math notranslate nohighlight">\((S)E(3)\)</span> to work with point cloud representations of molecules and how to implement, train and evaluate them. The dataset used here is not directly relevant to CADD, but the practical importance of <span class="math notranslate nohighlight">\((S)E(3)\)</span> equi-/invariance definitely carries over to more relevant applications such as protein ligand docking. Recent work on molecular representation learning also suggests that 3D point clouds are favored for a broad range
of property prediction tasks more relevant to CADD such as toxicity prediction.</p>
</section>
<section id="Caveats-of-our-approach">
<h3 id="Caveats-of-our-approach">Caveats of our approach<a class="headerlink" href="#Caveats-of-our-approach" title="Permalink to this heading">¶</a></h3>
<p>At this point, we should also go over some final caveats with the EGNN presented here and our approach in general:</p>
<ol class="arabic simple">
<li><p>Our model assumes that every atom interacts with every other atom, i.e. the neighborhood of node <span class="math notranslate nohighlight">\(i\)</span>, <span class="math notranslate nohighlight">\(N(i) = \{j \neq i\}\)</span> is complete. This approach has quadratic complexity meaning its more computationally expensive (go back to the model training and compare how long one epoch takes compared to the plain GNN) and thus might not be scalable to larger molecules. In this case we could restrict interactions by instead using</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(k\)</span>-nearest neighborhoods, i.e. <span class="math notranslate nohighlight">\(|N(i)| = k\)</span> contains the <span class="math notranslate nohighlight">\(k\)</span> nodes with the smallest euclidean distance to <span class="math notranslate nohighlight">\(i\)</span>,</p></li>
<li><p>or spherical neighborhoods with a fixed radius <span class="math notranslate nohighlight">\(\delta\)</span> instead, i.e. <span class="math notranslate nohighlight">\(N(i) = \{j \mid ||X_i - X_j||^2 \leq \delta\}\)</span></p></li>
</ul>
</li>
<li><p>Our EGNN model is <span class="math notranslate nohighlight">\(E(3)\)</span>-invariant. Note that some molecular properties are <em>sensitive</em> to reflection, In such settings, <span class="math notranslate nohighlight">\(SE(3)\)</span>-invariance should be the preferred model property (see <strong>Talktorial T033</strong>).</p></li>
<li><p>Random data splits are considered bad practice for measuring the capability of a molecular machine learning model to generalize to unseen data (see <a class="reference external" href="https://jcheminf.biomedcentral.com/articles/10.1186/s13321-019-0391-2">this paper</a> which analyzes and discusses this issue in-depth for QM9)</p></li>
</ol>
</section>
</section>
<section id="Quiz">
<h2 id="Quiz">Quiz<a class="headerlink" href="#Quiz" title="Permalink to this heading">¶</a></h2>
<ol class="arabic">
<li><p>In addition to 3D coordinates, what is strictly required for inference of covalent bonds between atoms?</p></li>
<li><p>What is the difference between equivariance and invariance?</p></li>
<li><p>True or false? <span class="math notranslate nohighlight">\(SE(3)\)</span> contains transformations which are not included in <span class="math notranslate nohighlight">\(E(3)\)</span>.</p></li>
<li><p>True or false? The atom embeddings <span class="math notranslate nohighlight">\(h\)</span> computed by iterating the following message passing scheme for a fixed number of steps are <span class="math notranslate nohighlight">\(E(3)\)</span>-invariant</p>
<div class="math notranslate nohighlight">
\[m_{ij}^{l} = \phi_{l}(h_i^l, h_j^l, X_i - X_j)\]</div>
<div class="math notranslate nohighlight">
\[h_{i}^{l+1} = \psi_l(h_{i}^l, \sum_{j \neq i} m_{ij}^l)\]</div>
</li>
</ol>
<script type="application/vnd.jupyter.widget-state+json">
{"state": {}, "version_major": 2, "version_minor": 0}
</script></section>
</section>


          </article>
        </div>
      </div>
    </main>
  </div>
  <footer class="md-footer">
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
          
            <a href="T035_graph_neural_networks.html" title="T035 · GNN-based molecular property prediction"
               class="md-flex md-footer-nav__link md-footer-nav__link--prev"
               rel="prev">
              <div class="md-flex__cell md-flex__cell--shrink">
                <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
              </div>
              <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
                <span class="md-flex__ellipsis">
                  <span
                      class="md-footer-nav__direction"> Previous </span> T035 · GNN-based molecular property prediction </span>
              </div>
            </a>
          
          
            <a href="T037_uncertainty_estimation.html" title="T037 · Uncertainty estimation"
               class="md-flex md-footer-nav__link md-footer-nav__link--next"
               rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title"><span
                class="md-flex__ellipsis"> <span
                class="md-footer-nav__direction"> Next </span> T037 · Uncertainty estimation </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink"><i
                class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          
        </a>
        
      </nav>
    </div>
    <div class="md-footer-meta md-typeset">
      <div class="md-footer-meta__inner md-grid">
        <div class="md-footer-copyright">
          <div class="md-footer-copyright__highlight">
              &#169; Copyright 2018-2023, Volkamer Lab. Project structure based on the Computational Molecular Science Python Cookiecutter version 1.1.
              
          </div>
            Created using
            <a href="http://www.sphinx-doc.org/">Sphinx</a> 7.1.2.
             and
            <a href="https://github.com/bashtage/sphinx-material/">Material for
              Sphinx</a>
        </div>
      </div>
    </div>
  </footer>
  <script src="../_static/javascripts/application.js"></script>
  <script>app.initialize({version: "1.0.4", url: {base: ".."}})</script>
  </body>
</html>