<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="T034 · RNN-based molecular property prediction" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://projects.volkamerlab.org/teachopencadd/talktorials/T034_recurrent_neural_networks.html" />
<meta property="og:site_name" content="TeachOpenCADD" />
<meta property="og:description" content="Note: This talktorial is a part of TeachOpenCADD, a platform that aims to teach domain-specific skills and to provide pipeline templates as starting points for research projects. Authors: Azat Tagirdzhanov, 2022, Chair for Clinical Bioinformatics, NextAID project, Saarland University. Aim of this..." />
<meta property="og:image" content="https://raw.githubusercontent.com/volkamerlab/teachopencadd/master/docs/_static/images/TeachOpenCADD_topics.png" />
<meta property="og:image:alt" content="TeachOpenCADD" />
<meta name="description" content="Note: This talktorial is a part of TeachOpenCADD, a platform that aims to teach domain-specific skills and to provide pipeline templates as starting points for research projects. Authors: Azat Tagirdzhanov, 2022, Chair for Clinical Bioinformatics, NextAID project, Saarland University. Aim of this..." />

  <meta name="viewport" content="width=device-width,initial-scale=1">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="lang:clipboard.copy" content="Copy to clipboard">
  <meta name="lang:clipboard.copied" content="Copied to clipboard">
  <meta name="lang:search.language" content="en">
  <meta name="lang:search.pipeline.stopwords" content="True">
  <meta name="lang:search.pipeline.trimmer" content="True">
  <meta name="lang:search.result.none" content="No matching documents">
  <meta name="lang:search.result.one" content="1 matching document">
  <meta name="lang:search.result.other" content="# matching documents">
  <meta name="lang:search.tokenizer" content="[\s\-]+">

  
    <link href="https://fonts.gstatic.com/" rel="preconnect" crossorigin>
    <link href="https://fonts.googleapis.com/css?family=Roboto+Mono:400,500,700|Roboto:300,400,400i,700&display=fallback" rel="stylesheet">

    <style>
      body,
      input {
        font-family: "Roboto", "Helvetica Neue", Helvetica, Arial, sans-serif
      }

      code,
      kbd,
      pre {
        font-family: "Roboto Mono", "Courier New", Courier, monospace
      }
    </style>
  

  <link rel="stylesheet" href="../_static/stylesheets/application.css"/>
  <link rel="stylesheet" href="../_static/stylesheets/application-palette.css"/>
  <link rel="stylesheet" href="../_static/stylesheets/application-fixes.css"/>
  
  <link rel="stylesheet" href="../_static/fonts/material-icons.css"/>
  
  <meta name="theme-color" content="#2196f3">
  <script src="../_static/javascripts/modernizr.js"></script>
  
    <script async src="../_static/cookieconsent.min.js"></script>
    <script>
        window.addEventListener("load", function(){
        window.cookieconsent.initialise({
            "palette": {
            "popup": {
                "background": "#f0f0f0",
                "text": "#999"
            },
            "button": {
                "text": "#fff",
                "background": "#009688"
            }
            },
            "theme": "classic"
        })});
    </script>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-Q6ZE82CNZB"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-Q6ZE82CNZB');
    </script>
  
    <link rel="apple-touch-icon" href="../_static/images/apple-icon-152x152.png"/>
  
  
    <title>T034 · RNN-based molecular property prediction &#8212; TeachOpenCADD 0 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/material.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/nbsphinx-code-cells.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="T035 · GNN-based molecular property prediction" href="T035_graph_neural_networks.html" />
    <link rel="prev" title="T033 · Molecular representations" href="T033_molecular_representations.html" />
  
    <link rel="apple-touch-icon" href="../_static/images/apple-icon-152x152.png"/>
  
   

  </head>
  <body dir=ltr
        data-md-color-primary=teal data-md-color-accent=cyan>
  
  <svg class="md-svg">
    <defs data-children-count="0">
      
      <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="__github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg>
      
    </defs>
  </svg>
  
  <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer">
  <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search">
  <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
  <a href="#talktorials/T034_recurrent_neural_networks" tabindex="1" class="md-skip"> Skip to content </a>
  <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex navheader">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="../index.html" title="TeachOpenCADD 0 documentation"
           class="md-header-nav__button md-logo">
          
            <i class="md-icon">school</i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          <span class="md-header-nav__topic">TeachOpenCADD</span>
          <span class="md-header-nav__topic"> T034 · RNN-based molecular property prediction </span>
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
        
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" action="../search.html" method="get" name="search">
      <input type="text" class="md-search__input" name="q" placeholder="Search"
             autocapitalize="off" autocomplete="off" spellcheck="false"
             data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>

      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            <a href="https://github.com/volkamerlab/teachopencadd/" title="Go to repository" class="md-source" data-md-source="github">

    <div class="md-source__icon">
      <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 24 24" width="28" height="28">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    TeachOpenCADD
  </div>
</a>
          </div>
        </div>
      
      
    </div>
  </nav>
</header>

  
  <div class="md-container">
    
    
    
  <nav class="md-tabs" data-md-component="tabs">
    <div class="md-tabs__inner md-grid">
      <ul class="md-tabs__list">
            
            <li class="md-tabs__item"><a href="../talktorials.html" class="md-tabs__link">Our talktorials</a></li>
            
            <li class="md-tabs__item"><a href="../installing.html" class="md-tabs__link">Run locally</a></li>
            
            <li class="md-tabs__item"><a href="../contribute.html" class="md-tabs__link">Development</a></li>
            
            <li class="md-tabs__item"><a href="../contact.html" class="md-tabs__link">Contact</a></li>
            
            <li class="md-tabs__item"><a href="../citation.html" class="md-tabs__link">Citation</a></li>
          <li class="md-tabs__item"><a href="../all_talktorials.html" class="md-tabs__link">Complete list of talktorials</a></li>
      </ul>
    </div>
  </nav>
    <main class="md-main">
      <div class="md-main__inner md-grid" data-md-component="container">
        
          <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="../index.html" title="TeachOpenCADD 0 documentation" class="md-nav__button md-logo">
      
        <i class="md-icon">school</i>
      
    </a>
    <a href="../index.html"
       title="TeachOpenCADD 0 documentation">TeachOpenCADD</a>
  </label>
    <div class="md-nav__source">
      <a href="https://github.com/volkamerlab/teachopencadd/" title="Go to repository" class="md-source" data-md-source="github">

    <div class="md-source__icon">
      <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 24 24" width="28" height="28">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    TeachOpenCADD
  </div>
</a>
    </div>
  
  

  
  <ul class="md-nav__list">
    <li class="md-nav__item">
    
      <span class="md-nav__link caption"><span class="caption-text">Our talktorials</span></span>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../all_talktorials.html" class="md-nav__link">Complete list of talktorials</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../talktorials.html" class="md-nav__link">Talktorials by collection</a>
      <ul class="md-nav__list"> 
    <li class="md-nav__item">
    
    
      <a href="../talktorials.html#edition-2019-jcim" class="md-nav__link">Edition 2019 - JCIM</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../talktorials.html#edition-2021" class="md-nav__link">Edition 2021</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../talktorials.html#ligand-based-cheminformatics" class="md-nav__link">Ligand-based cheminformatics</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../talktorials.html#structural-biology" class="md-nav__link">Structural biology</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../talktorials.html#online-apis-servers" class="md-nav__link">Online APIs/servers</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../talktorials.html#kinase-similarity" class="md-nav__link">Kinase similarity</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../talktorials.html#deep-learning" class="md-nav__link">Deep learning</a>
      
    
    </li></ul>
    
    </li>
    <li class="md-nav__item">
    
      <span class="md-nav__link caption"><span class="caption-text">Run locally</span></span>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../installing.html" class="md-nav__link">Installing</a>
      
    
    </li>
    <li class="md-nav__item">
    
      <span class="md-nav__link caption"><span class="caption-text">Development</span></span>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../contribute.html" class="md-nav__link">For contributors</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../api.html" class="md-nav__link">API Documentation</a>
      
    
    </li>
    <li class="md-nav__item">
    
      <span class="md-nav__link caption"><span class="caption-text">About TeachOpenCADD</span></span>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../contact.html" class="md-nav__link">Contact</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../acknowledgments.html" class="md-nav__link">Acknowledgments</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../citation.html" class="md-nav__link">Citation</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../license.html" class="md-nav__link">License</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../funding.html" class="md-nav__link">Funding</a>
      
    
    </li>
    <li class="md-nav__item">
    
      <span class="md-nav__link caption"><span class="caption-text">External resources</span></span>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../external_dependencies.html" class="md-nav__link">Packages and webservers used in TeachOpenCADD</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../external_tutorials_collections.html" class="md-nav__link">External tutorials and collections</a>
      
    
    </li>
  </ul>
  

</nav>
              </div>
            </div>
          </div>
          <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                
<nav class="md-nav md-nav--secondary">
    <label class="md-nav__title" for="__toc">Contents</label>
  <ul class="md-nav__list" data-md-scrollfix="">
        <li class="md-nav__item"><a href="#talktorials-t034-recurrent-neural-networks--page-root" class="md-nav__link">T034 · RNN-based molecular property prediction</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#Aim-of-this-talktorial" class="md-nav__link">Aim of this talktorial</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#Contents-in-Theory" class="md-nav__link">Contents in <em>Theory</em></a>
        </li>
        <li class="md-nav__item"><a href="#Contents-in-Practical" class="md-nav__link">Contents in <em>Practical</em></a>
        </li>
        <li class="md-nav__item"><a href="#References" class="md-nav__link">References</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#Talktorials" class="md-nav__link">Talktorials</a>
        </li>
        <li class="md-nav__item"><a href="#Theoretical-background" class="md-nav__link">Theoretical background</a>
        </li></ul>
            </nav>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#Theory" class="md-nav__link">Theory</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#Molecules-as-text" class="md-nav__link">Molecules as text</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#Tokenization-and-one-hot-encoding" class="md-nav__link">Tokenization and one-hot encoding</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#Recurrent-Neural-Networks-(RNNs)" class="md-nav__link">Recurrent Neural Networks (RNNs)</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#Vanilla-RNN" class="md-nav__link">Vanilla RNN</a>
        </li>
        <li class="md-nav__item"><a href="#Training-an-RNN" class="md-nav__link">Training an RNN</a>
        </li>
        <li class="md-nav__item"><a href="#Vanishing-gradients" class="md-nav__link">Vanishing gradients</a>
        </li>
        <li class="md-nav__item"><a href="#Gated-Recurrent-Unit" class="md-nav__link">Gated Recurrent Unit</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#Reset-gate" class="md-nav__link">Reset gate</a>
        </li>
        <li class="md-nav__item"><a href="#Update-gate" class="md-nav__link">Update gate</a>
        </li>
        <li class="md-nav__item"><a href="#Hidden-state-candidate" class="md-nav__link">Hidden state candidate</a>
        </li>
        <li class="md-nav__item"><a href="#Hidden-state-update" class="md-nav__link">Hidden state update</a>
        </li></ul>
            </nav>
        </li></ul>
            </nav>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#Practical" class="md-nav__link">Practical</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#Dataset" class="md-nav__link">Dataset</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#Preprocessing" class="md-nav__link">Preprocessing</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#Models" class="md-nav__link">Models</a>
        </li>
        <li class="md-nav__item"><a href="#Training" class="md-nav__link">Training</a>
        </li>
        <li class="md-nav__item"><a href="#Evaluation" class="md-nav__link">Evaluation</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#Discussion" class="md-nav__link">Discussion</a>
        </li>
        <li class="md-nav__item"><a href="#Quiz" class="md-nav__link">Quiz</a>
        </li></ul>
            </nav>
        </li>
    
<li class="md-nav__item"><a class="md-nav__extra_link" href="../_sources/talktorials/T034_recurrent_neural_networks.nblink.txt">Show Source</a> </li>

<li id="searchbox" class="md-nav__item"></li>

  </ul>
</nav>
              </div>
            </div>
          </div>
        
        <div class="md-content">
          <article class="md-content__inner md-typeset" role="main">
            
  <section id="T034-·-RNN-based-molecular-property-prediction">
<h1 id="talktorials-t034-recurrent-neural-networks--page-root">T034 · RNN-based molecular property prediction<a class="headerlink" href="#talktorials-t034-recurrent-neural-networks--page-root" title="Permalink to this heading">¶</a></h1>
<p><strong>Note:</strong> This talktorial is a part of TeachOpenCADD, a platform that aims to teach domain-specific skills and to provide pipeline templates as starting points for research projects.</p>
<p>Authors:</p>
<ul class="simple">
<li><p>Azat Tagirdzhanov, 2022, <a class="reference external" href="https://www.ccb.uni-saarland.de/">Chair for Clinical Bioinformatics</a>, <a class="reference external" href="https://nextaid.cs.uni-saarland.de/">NextAID</a> project, Saarland University</p></li>
</ul>
<section id="Aim-of-this-talktorial">
<h2 id="Aim-of-this-talktorial">Aim of this talktorial<a class="headerlink" href="#Aim-of-this-talktorial" title="Permalink to this heading">¶</a></h2>
<p>Molecular representation by a SMILES string paved the way for applying natural language processing techniques to a broad range of molecule-related tasks. In this talktorial we will dive deeper into one of these techniques: recurrent neural networks (RNNs). First, we will describe different RNN architectures and then apply them to a regression task using the QM9 dataset.</p>
<section id="Contents-in-Theory">
<h3 id="Contents-in-Theory">Contents in <em>Theory</em><a class="headerlink" href="#Contents-in-Theory" title="Permalink to this heading">¶</a></h3>
<ul class="simple">
<li><p>Molecules as text</p>
<ul>
<li><p>Tokenization and one-hot encoding</p></li>
</ul>
</li>
<li><p>Recurrent Neural Networks (RNNs)</p>
<ul>
<li><p>Vanilla RNN</p></li>
<li><p>Training an RNN</p></li>
<li><p>Vanishing gradients</p></li>
<li><p>Gated Recurrent Unit</p></li>
</ul>
</li>
</ul>
</section>
<section id="Contents-in-Practical">
<h3 id="Contents-in-Practical">Contents in <em>Practical</em><a class="headerlink" href="#Contents-in-Practical" title="Permalink to this heading">¶</a></h3>
<ul class="simple">
<li><p>Dataset</p></li>
<li><p>Model definition</p></li>
<li><p>Training</p></li>
<li><p>Evaluation</p></li>
</ul>
</section>
<section id="References">
<h3 id="References">References<a class="headerlink" href="#References" title="Permalink to this heading">¶</a></h3>
<section id="Talktorials">
<h4 id="Talktorials">Talktorials<a class="headerlink" href="#Talktorials" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p><strong>Talktorial T021</strong>: One-Hot Encoding</p></li>
<li><p><strong>Talktorial T022</strong>: Ligand-based screening: neural networks</p></li>
<li><p><strong>Talktorial T033</strong>: Molecular Representations</p></li>
<li><p><strong>Talktorial T034</strong>: GNN based property prediction</p></li>
</ul>
</section>
<section id="Theoretical-background">
<h4 id="Theoretical-background">Theoretical background<a class="headerlink" href="#Theoretical-background" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p>Michael Phi, Illustrated Guide to Recurrent Neural Networks, <a class="reference external" href="https://towardsdatascience.com/illustrated-guide-to-recurrent-neural-networks-79e5eb8049c9">towardsdatascience</a></p></li>
<li><p>Michael Phi, Illustrated Guide to LSTM’s and GRU’s: A step by-step explanation, <a class="reference external" href="https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21">towardsdatascience</a></p></li>
<li><p><a class="reference external" href="https://d2l.ai/chapter_recurrent-modern/index.html">Modern Recurrent Neural Networks</a>, D2L.ai: Interactive Deep Learning Book with Multi-Framework Code, Math, and Discussions</p></li>
<li><p>Denny Britz, Recurrent Neural Networks Tutorial, <a class="reference external" href="https://dennybritz.com/posts/wildml/recurrent-neural-networks-tutorial-part-1/">dennybritz.com</a></p></li>
<li><p>Andrej Karpathy, The Unreasonable Effectiveness of Recurrent Neural Networks, <a class="reference external" href="https://karpathy.github.io/2015/05/21/rnn-effectiveness/">Andrej Karpathy blog</a></p></li>
</ul>
</section>
</section>
</section>
<section id="Theory">
<h2 id="Theory">Theory<a class="headerlink" href="#Theory" title="Permalink to this heading">¶</a></h2>
<section id="Molecules-as-text">
<h3 id="Molecules-as-text">Molecules as text<a class="headerlink" href="#Molecules-as-text" title="Permalink to this heading">¶</a></h3>
<p>To apply machine learning to molecular data, it is necessary to first convert the molecules into a representation that can be used as input to the machine learning models. We have already discussed numerous ways of molecular representations in <strong>Talktorial T033</strong>. In this talktorial we will be using a textual representation of molecules by SMILES strings.</p>
<p>The string representation of molecules paves the way for applying natural language processing (NLP) techniques to molecular data. In recent years, there has been significant progress in NLP models including, most famously, recurrent neural networks and transformers. These models proved to be good at capturing text semantics and, when applied to SMILES strings, can capture the structure of the molecule in its textual representation.</p>
<section id="Tokenization-and-one-hot-encoding">
<h4 id="Tokenization-and-one-hot-encoding">Tokenization and one-hot encoding<a class="headerlink" href="#Tokenization-and-one-hot-encoding" title="Permalink to this heading">¶</a></h4>
<p>Like other machine learning models, NLP models are designed to operate with numeric inputs. We have already discussed how to transform SMILES strings into numerical form in <strong>Talktorial T021</strong>. Here, we will only briefly go through the key steps: - To transform a string into a sequence of vectors, the string is first split into meaningful chunks called <em>tokens</em>. For example, one way of tokenizing a SMILES string <code class="docutils literal notranslate"><span class="pre">C=CCl</span></code> is to split it into individual atomic and branch symbols:
<code class="docutils literal notranslate"><span class="pre">[C,</span> <span class="pre">=,</span> <span class="pre">C,</span> <span class="pre">Cl]</span></code>. - All possible tokens form a <em>vocabulary</em>. The vocabulary is usually derived from the dataset and contains a fixed amount of the most common tokens among all the data. Depending on the application, the vocabulary might also contain special tokens marking out-of-vocabulary tokens, padding symbols, and more. In our example, only limited to this particular compound, the vocabulary will look like <code class="docutils literal notranslate"><span class="pre">[C,</span> <span class="pre">Cl,</span> <span class="pre">=]</span></code>. Replacing the tokens with their indices in the vocabulary gets us to
another representation, <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">2,</span> <span class="pre">0,</span> <span class="pre">1]</span></code>. - Finally, the sequence of token indices is transformed to a sequence of binary vectors using one-hot encoding:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{bmatrix} 1 \\ 0 \\ 0 \end{bmatrix},~
\begin{bmatrix} 0 \\ 0 \\ 1 \end{bmatrix},~
\begin{bmatrix} 1 \\ 0 \\ 0 \end{bmatrix},~
\begin{bmatrix} 0 \\ 1 \\ 0 \end{bmatrix}.\end{split}\]</div>
</section>
</section>
<section id="Recurrent-Neural-Networks-(RNNs)">
<h3 id="Recurrent-Neural-Networks-(RNNs)">Recurrent Neural Networks (RNNs)<a class="headerlink" href="#Recurrent-Neural-Networks-(RNNs)" title="Permalink to this heading">¶</a></h3>
<p>Recurrent neural networks (RNNs) are designed to handle sequential data. To do so, they introduce the notion of time. Elements of the input sequence are processed one after another, with the output of the current time step being passed to the next one as an additional input. This is done by introducing a special type of connection called a <em>recurrent connection</em> (hence the name). This architecture allows RNNs to accumulate information about the past and as a result capture dependencies between
elements in the sequence.</p>
<p>The figure below illustrates the basic principle of an RNN. An RNN cell has a hidden state vector <span class="math notranslate nohighlight">\(h_t\)</span> which is updated at each time step <span class="math notranslate nohighlight">\(t\)</span> and is responsible for aggregating the information about the previous elements of the input sequence. The update is performed by combining the input <span class="math notranslate nohighlight">\(x_t\)</span> with the hidden state of the previous step <span class="math notranslate nohighlight">\(h_{t-1}\)</span>, passed to the RNN cell by the recurrent connection (Figure 1, on the left).</p>
<p>To better visualize how RNN processes sequences of data it is helpful to unfold the network in time (Figure 1, on the right). The RNN is unfolded by duplicating each unit at each time step and sharing the weights and biases across all the units. The unfolded representation shows that RNNs can be viewed as feed-forward neural networks with shared parameters.</p>
<img alt="RNN" src="../_images/rnn-unfolded-800.png"/>
<p><em>Figure 1:</em> Two ways of representing a recurrent neural network: compressed (left) and unfolded in time (right).</p>
<p>The mechanism behind the computation of the hidden state varies depending on the architecture. Examples of RNN architectures include Vanilla RNN, Long Short-Term Memory (LSTM), and Gated Recurrent Units (GRUs).</p>
<section id="Vanilla-RNN">
<h4 id="Vanilla-RNN">Vanilla RNN<a class="headerlink" href="#Vanilla-RNN" title="Permalink to this heading">¶</a></h4>
<p>In a Vanilla RNN the hidden state is updated according to the following recurrence relation,</p>
<div class="math notranslate nohighlight">
\[h_{t} = \tanh( W x_{t} + U h_{t-1} + b),~~~t=1,2,\dots,L.\]</div>
<p>Here <span class="math notranslate nohighlight">\(W\)</span> and <span class="math notranslate nohighlight">\(U\)</span> are weight matrices, and <span class="math notranslate nohighlight">\(b\)</span> is a bias vector. The initial hidden state <span class="math notranslate nohighlight">\(h_0\)</span> is usually seeded as a vector of zeros. Model weights <span class="math notranslate nohighlight">\(W\)</span>, <span class="math notranslate nohighlight">\(U\)</span> and <span class="math notranslate nohighlight">\(b\)</span> are shared between all the time steps.</p>
</section>
<section id="Training-an-RNN">
<h4 id="Training-an-RNN">Training an RNN<a class="headerlink" href="#Training-an-RNN" title="Permalink to this heading">¶</a></h4>
<p>Similar to other neural networks, RNNs are trained using a backpropagation algorithm. A flavor of the algorithm used in RNNs is called <em>backpropagation through time</em> or BPTT for short. BPTT applies backpropagation to the unfolded network to compute the gradient of the loss function for the network weights taking into account parameter sharing.</p>
</section>
<section id="Vanishing-gradients">
<h4 id="Vanishing-gradients">Vanishing gradients<a class="headerlink" href="#Vanishing-gradients" title="Permalink to this heading">¶</a></h4>
<p>Vanilla RNNs are susceptible to a problem called <em>vanishing gradients</em>. This problem occurs in deep neural networks when the gradients of the weights of the first layers of the network become very small as they are backpropagated through the network. This can lead to slow training and poor performance. In RNNs, the backpropagation is applied to the unfolded network which tends to be very deep. Furthermore, all copies of the RNN cells in the unfolded network share the same weights, which can
cause gradients to diminish exponentially fast. For more details on the vanishing gradients problem, please refer to the blog post: <a class="reference external" href="https://dennybritz.com/posts/wildml/recurrent-neural-networks-tutorial-part-3/">Backpropagation Through Time and Vanishing Gradients</a>.</p>
</section>
<section id="Gated-Recurrent-Unit">
<h4 id="Gated-Recurrent-Unit">Gated Recurrent Unit<a class="headerlink" href="#Gated-Recurrent-Unit" title="Permalink to this heading">¶</a></h4>
<p>A Gated recurrent unit (GRU) is a more advanced architecture of the recurrent network that aims to solve the vanishing gradient problem. In addition to the hidden state vector, GRU introduces the so-called <em>update gate</em> and <em>reset gate</em>. These two vectors help the model to decide which information should be passed forward. They can be trained to keep information from long ago, without washing it through time or removing information that is irrelevant to the prediction.</p>
<section id="Reset-gate">
<h5 id="Reset-gate">Reset gate<a class="headerlink" href="#Reset-gate" title="Permalink to this heading">¶</a></h5>
<p>This gate is used by the GRU cell to decide how much of the past information to forget. It is calculated using the formula</p>
<div class="math notranslate nohighlight">
\[r_t = \sigma(W_{r} x_t + U_{r} h_{t-1} + b_r).\]</div>
<p>The input vector <span class="math notranslate nohighlight">\(x_t\)</span> is multiplied by the weight matrix <span class="math notranslate nohighlight">\(W_r\)</span>. The hidden state from the previous time steps <span class="math notranslate nohighlight">\(h_{t-1}\)</span> is also plugged into the cell and is multiplied by its weight matrix <span class="math notranslate nohighlight">\(U_r\)</span>. Both results are added together with a bias vector <span class="math notranslate nohighlight">\(b_r\)</span> and passed through a sigmoid activation function to limit the output to a range between 0 and 1.</p>
</section>
<section id="Update-gate">
<h5 id="Update-gate">Update gate<a class="headerlink" href="#Update-gate" title="Permalink to this heading">¶</a></h5>
<p>The update gate is calculated using a similar formula,</p>
<div class="math notranslate nohighlight">
\[z_t = \sigma(W_{z} x_t + U_{z} h_{t-1} + b_z),\]</div>
<p>but it has its own weights <span class="math notranslate nohighlight">\(W_z\)</span>, <span class="math notranslate nohighlight">\(U_z\)</span>, <span class="math notranslate nohighlight">\(b_z\)</span>, and serves a different purpose. As we will see below, the update gate helps the GRU cell to decide how much of the past information should be passed to the future step.</p>
</section>
<section id="Hidden-state-candidate">
<h5 id="Hidden-state-candidate">Hidden state candidate<a class="headerlink" href="#Hidden-state-candidate" title="Permalink to this heading">¶</a></h5>
<p>A candidate’s hidden state stores the relevant information from the past. It is calculated as follows:</p>
<div class="math notranslate nohighlight">
\[\hat{h}_t = \tanh(W_{h} x_t + U_{h}(r_t \odot h_{t-1}) + b_h),\]</div>
<p>where <span class="math notranslate nohighlight">\(\odot\)</span> is the <a class="reference external" href="https://en.wikipedia.org/wiki/Hadamard_product_(matrices)">element-wise product</a> and <span class="math notranslate nohighlight">\(r_t\)</span> is the reset gate vector introduced above. This formula looks similar to how the hidden state is updated in a simple RNN cell, but here the hidden state from the previous time step <span class="math notranslate nohighlight">\(h_{t-1}\)</span> is multiplied by the reset gate vector <span class="math notranslate nohighlight">\(r_t\)</span>. Due to sigmoid activation, components of <span class="math notranslate nohighlight">\(r_t\)</span> take values between 0 and 1. Using the reset gate the model can learn
which information is not relevant and should be discarded. If, for example, an <span class="math notranslate nohighlight">\(i\)</span>-th component of <span class="math notranslate nohighlight">\(r_t\)</span> is close to 0, then the memory contained in the <span class="math notranslate nohighlight">\(i\)</span>-th component of <span class="math notranslate nohighlight">\(h_{t-1}\)</span> will be discarded in the candidate vector.</p>
</section>
<section id="Hidden-state-update">
<h5 id="Hidden-state-update">Hidden state update<a class="headerlink" href="#Hidden-state-update" title="Permalink to this heading">¶</a></h5>
<p>Finally, the hidden state is updated as a mixture of <span class="math notranslate nohighlight">\(h_{t-1}\)</span> and the hidden state candidate,</p>
<div class="math notranslate nohighlight">
\[h_t =   z_t \odot h_{t-1} + (1-z_t) \odot  \hat{h}_t.\]</div>
<p>Here, the update gate vector <span class="math notranslate nohighlight">\(z_t\)</span> controls how much information to collect from the candidate vector <span class="math notranslate nohighlight">\(\hat{h}_t\)</span> and how much from the previous steps <span class="math notranslate nohighlight">\(h_{t-1}\)</span>.</p>
</section>
</section>
</section>
</section>
<section id="Practical">
<h2 id="Practical">Practical<a class="headerlink" href="#Practical" title="Permalink to this heading">¶</a></h2>
<p>In the practical section, we will apply recurrent neural networks to a regression task.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[48]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">torch.nn.utils.rnn</span> <span class="kn">import</span> <span class="n">pad_sequence</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">Subset</span><span class="p">,</span> <span class="n">TensorDataset</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[49]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Use cuda if available</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>

<span class="c1"># seed random generator</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[50]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">HERE</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">_dh</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="n">DATA</span> <span class="o">=</span> <span class="n">HERE</span> <span class="o">/</span> <span class="s2">"data"</span>
</pre></div>
</div>
</div>
<section id="Dataset">
<h3 id="Dataset">Dataset<a class="headerlink" href="#Dataset" title="Permalink to this heading">¶</a></h3>
<p>In this talktorial we use <a class="reference external" href="https://pytorch-geometric.readthedocs.io/en/2.2.0/modules/datasets.html#torch_geometric.datasets.QM9">QM9</a> dataset from the <a class="reference external" href="https://arxiv.org/abs/1703.00564">MoleculeNet</a> paper. This dataset consists of about 130,000 molecules together with their quantum chemical properties.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[51]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># load the dataset</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA</span><span class="p">,</span> <span class="s2">"qm9.csv.gz"</span><span class="p">),</span> <span class="n">compression</span><span class="o">=</span><span class="s2">"gzip"</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[51]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th></th>
<th>mol_id</th>
<th>A</th>
<th>B</th>
<th>C</th>
<th>mu</th>
<th>alpha</th>
<th>homo</th>
<th>lumo</th>
<th>gap</th>
<th>r2</th>
<th>...</th>
<th>u0</th>
<th>u298</th>
<th>h298</th>
<th>g298</th>
<th>cv</th>
<th>u0_atom</th>
<th>u298_atom</th>
<th>h298_atom</th>
<th>g298_atom</th>
<th>smiles</th>
</tr>
</thead>
<tbody>
<tr>
<th>0</th>
<td>gdb_1</td>
<td>157.71180</td>
<td>157.709970</td>
<td>157.706990</td>
<td>0.0000</td>
<td>13.21</td>
<td>-0.3877</td>
<td>0.1171</td>
<td>0.5048</td>
<td>35.3641</td>
<td>...</td>
<td>-40.478930</td>
<td>-40.476062</td>
<td>-40.475117</td>
<td>-40.498597</td>
<td>6.469</td>
<td>-395.999595</td>
<td>-398.643290</td>
<td>-401.014647</td>
<td>-372.471772</td>
<td>C</td>
</tr>
<tr>
<th>1</th>
<td>gdb_2</td>
<td>293.60975</td>
<td>293.541110</td>
<td>191.393970</td>
<td>1.6256</td>
<td>9.46</td>
<td>-0.2570</td>
<td>0.0829</td>
<td>0.3399</td>
<td>26.1563</td>
<td>...</td>
<td>-56.525887</td>
<td>-56.523026</td>
<td>-56.522082</td>
<td>-56.544961</td>
<td>6.316</td>
<td>-276.861363</td>
<td>-278.620271</td>
<td>-280.399259</td>
<td>-259.338802</td>
<td>N</td>
</tr>
<tr>
<th>2</th>
<td>gdb_3</td>
<td>799.58812</td>
<td>437.903860</td>
<td>282.945450</td>
<td>1.8511</td>
<td>6.31</td>
<td>-0.2928</td>
<td>0.0687</td>
<td>0.3615</td>
<td>19.0002</td>
<td>...</td>
<td>-76.404702</td>
<td>-76.401867</td>
<td>-76.400922</td>
<td>-76.422349</td>
<td>6.002</td>
<td>-213.087624</td>
<td>-213.974294</td>
<td>-215.159658</td>
<td>-201.407171</td>
<td>O</td>
</tr>
<tr>
<th>3</th>
<td>gdb_4</td>
<td>0.00000</td>
<td>35.610036</td>
<td>35.610036</td>
<td>0.0000</td>
<td>16.28</td>
<td>-0.2845</td>
<td>0.0506</td>
<td>0.3351</td>
<td>59.5248</td>
<td>...</td>
<td>-77.308427</td>
<td>-77.305527</td>
<td>-77.304583</td>
<td>-77.327429</td>
<td>8.574</td>
<td>-385.501997</td>
<td>-387.237686</td>
<td>-389.016047</td>
<td>-365.800724</td>
<td>C#C</td>
</tr>
<tr>
<th>4</th>
<td>gdb_5</td>
<td>0.00000</td>
<td>44.593883</td>
<td>44.593883</td>
<td>2.8937</td>
<td>12.99</td>
<td>-0.3604</td>
<td>0.0191</td>
<td>0.3796</td>
<td>48.7476</td>
<td>...</td>
<td>-93.411888</td>
<td>-93.409370</td>
<td>-93.408425</td>
<td>-93.431246</td>
<td>6.278</td>
<td>-301.820534</td>
<td>-302.906752</td>
<td>-304.091489</td>
<td>-288.720028</td>
<td>C#N</td>
</tr>
</tbody>
</table>
<p>5 rows × 21 columns</p>
</div></div>
</div>
<p>In this talktorial we will build a model predicting one of the properties – the dipole moment <code class="docutils literal notranslate"><span class="pre">mu</span></code> – based on the string representation of the molecule provided in the <code class="docutils literal notranslate"><span class="pre">smiles</span></code> column in the table above.</p>
<section id="Preprocessing">
<h4 id="Preprocessing">Preprocessing<a class="headerlink" href="#Preprocessing" title="Permalink to this heading">¶</a></h4>
<p>First, define the classes and helper functions we will be using for the data preprocessing</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[52]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">SmilesTokenizer</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    A simple regex-based tokenizer adapted from the deepchem smiles_tokenizer package.</span>
<span class="sd">    SMILES regex pattern for the tokenization is designed by Schwaller et. al., ACS Cent. Sci 5 (2019)</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">regex_pattern</span> <span class="o">=</span> <span class="p">(</span>
            <span class="sa">r</span><span class="s2">"(\[[^\]]+]|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\(|\)|\."</span>
            <span class="sa">r</span><span class="s2">"|=|#|-|\+|</span><span class="se">\\</span><span class="s2">|\/|:|~|@|\?|&gt;&gt;?|\*|\$|\%[0-9]</span><span class="si">{2}</span><span class="s2">|[0-9])"</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">regex</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">regex_pattern</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">tokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">smiles</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Tokenizes SMILES string.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        smiles : str</span>
<span class="sd">            Input SMILES string.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        List[str]</span>
<span class="sd">            A list of tokens.</span>
<span class="sd">        """</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">token</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">regex</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="n">smiles</span><span class="p">)]</span>
        <span class="k">return</span> <span class="n">tokens</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[53]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">build_vocab</span><span class="p">(</span><span class="n">smiles_list</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">max_vocab_size</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Builds a vocabulary of N=max_vocab_size most common tokens from list of SMILES strings.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    smiles_list : List[str]</span>
<span class="sd">        List of SMILES strings.</span>
<span class="sd">    tokenizer : SmilesTokenizer</span>
<span class="sd">    max_vocab_size : int</span>
<span class="sd">        Maximum size of vocabulary.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Dict[str, int]</span>
<span class="sd">        A dictionary that defines mapping of a token to its index in the vocabulary.</span>
<span class="sd">    """</span>
    <span class="n">tokenized_smiles</span> <span class="o">=</span> <span class="p">[</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">smiles_list</span><span class="p">]</span>
    <span class="n">token_counter</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">c</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">tokenized_smiles</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">s</span><span class="p">)</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">token</span> <span class="k">for</span> <span class="n">token</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">token_counter</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="n">max_vocab_size</span><span class="p">)]</span>
    <span class="n">vocab</span> <span class="o">=</span> <span class="p">{</span><span class="n">token</span><span class="p">:</span> <span class="n">idx</span> <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">token</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tokens</span><span class="p">)}</span>
    <span class="k">return</span> <span class="n">vocab</span>


<span class="k">def</span> <span class="nf">smiles_to_ohe</span><span class="p">(</span><span class="n">smiles</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">vocab</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Transforms SMILES string to one-hot encoding representation.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    smiles : str</span>
<span class="sd">        Input SMILES string.</span>
<span class="sd">    tokenizer : SmilesTokenizer</span>
<span class="sd">    vocab : Dict[str, int]</span>
<span class="sd">        A dictionary that defines mapping of a token to its index in the vocabulary.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Tensor</span>
<span class="sd">        A pytorch Tensor with shape (n_tokens, vocab_size), where n_tokens is the</span>
<span class="sd">        length of tokenized input string, vocab_size is the number of tokens in</span>
<span class="sd">        the vocabulary</span>
<span class="sd">    """</span>
    <span class="n">unknown_token_id</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">token_ids</span> <span class="o">=</span> <span class="p">[</span><span class="n">vocab</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">token</span><span class="p">,</span> <span class="n">unknown_token_id</span><span class="p">)</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">smiles</span><span class="p">)]</span>
    <span class="n">ohe</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">))[</span><span class="n">token_ids</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">ohe</span>
</pre></div>
</div>
</div>
<p>Let’s have a look at how these functions work with a simple example. Here, we will be using the same SMILES string as in the Theoretical section.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[54]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">SmilesTokenizer</span><span class="p">()</span>

<span class="n">smiles</span> <span class="o">=</span> <span class="s2">"C=CCl"</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"SMILES string:</span><span class="se">\n\t</span><span class="s2">"</span><span class="p">,</span> <span class="n">smiles</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Tokens:</span><span class="se">\n\t</span><span class="s2">"</span><span class="p">,</span> <span class="s2">", "</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">smiles</span><span class="p">)))</span>
<span class="n">vocab</span> <span class="o">=</span> <span class="n">build_vocab</span><span class="p">([</span><span class="n">smiles</span><span class="p">],</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Vocab:</span><span class="se">\n\t</span><span class="s2">"</span><span class="p">,</span> <span class="n">vocab</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"OHE:</span><span class="se">\n</span><span class="s2">"</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">smiles_to_ohe</span><span class="p">(</span><span class="n">smiles</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">vocab</span><span class="p">))</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
SMILES string:
         C=CCl
Tokens:
         C, =, C, Cl
Vocab:
         {'C': 0, '=': 1, 'Cl': 2}
OHE:
 [[1. 0. 1. 0.]
 [0. 1. 0. 0.]
 [0. 0. 0. 1.]]
</pre></div></div>
</div>
<p>Now, we apply these preprocessing steps to our data. For the sake of reducing the runtime, we will be using only a random subset of the whole QM9 dataset. The dataset is split into training, validation and test sets. We build the vocabulary and define the transformation of the target based only on the training set.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[55]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sample_size</span> <span class="o">=</span> <span class="mi">50000</span>
<span class="n">n_train</span> <span class="o">=</span> <span class="mi">40000</span>
<span class="n">n_test</span> <span class="o">=</span> <span class="n">n_val</span> <span class="o">=</span> <span class="mi">5000</span>

<span class="c1"># get a sample</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">sample_size</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># select columns from the data frame</span>
<span class="n">smiles</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">"smiles"</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">"mu"</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>

<span class="c1"># build a vocab using the training data</span>
<span class="n">max_vocab_size</span> <span class="o">=</span> <span class="mi">30</span>
<span class="n">vocab</span> <span class="o">=</span> <span class="n">build_vocab</span><span class="p">(</span><span class="n">smiles</span><span class="p">[:</span><span class="n">n_train</span><span class="p">],</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">max_vocab_size</span><span class="p">)</span>
<span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span>

<span class="c1"># transform smiles to one-hot encoded tensors and apply padding</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">pad_sequence</span><span class="p">(</span>
    <span class="n">sequences</span><span class="o">=</span><span class="p">[</span><span class="n">smiles_to_ohe</span><span class="p">(</span><span class="n">smi</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">vocab</span><span class="p">)</span> <span class="k">for</span> <span class="n">smi</span> <span class="ow">in</span> <span class="n">smiles</span><span class="p">],</span>
    <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">padding_value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># normalize the target using the training data</span>
<span class="n">train_mean</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:</span><span class="n">n_train</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">train_std</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:</span><span class="n">n_train</span><span class="p">]</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">train_mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">train_std</span>

<span class="c1"># build dataset</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>

<span class="c1"># define loaders</span>
<span class="n">ids_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_train</span><span class="p">)</span>
<span class="n">ids_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_val</span><span class="p">)</span> <span class="o">+</span> <span class="n">n_train</span>
<span class="n">ids_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_test</span><span class="p">)</span> <span class="o">+</span> <span class="n">n_train</span> <span class="o">+</span> <span class="n">n_val</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">Subset</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">ids_train</span><span class="p">),</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">generator</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Generator</span><span class="p">()</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">),</span>
<span class="p">)</span>
<span class="n">val_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">Subset</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">ids_val</span><span class="p">),</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Generator</span><span class="p">()</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">Subset</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">ids_test</span><span class="p">),</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">generator</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Generator</span><span class="p">()</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</section>
</section>
<section id="Models">
<h3 id="Models">Models<a class="headerlink" href="#Models" title="Permalink to this heading">¶</a></h3>
<p>In this talktorial we compare two recurrent networks. Both of them contain a single recurrent layer followed by a fully-connected layer transforming the hidden state from the last time step to a one-dimensional output. In the <code class="docutils literal notranslate"><span class="pre">RNNRegressionModel</span></code> we use a vanilla RNN architecture, while in <code class="docutils literal notranslate"><span class="pre">GRURegressionModel</span></code> a more advanced GRU architecture.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[56]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">RNNRegressionModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Vanilla RNN with one recurrent layer"""</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Vanilla RNN</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        input_size : int</span>
<span class="sd">            The number of expected features in the input vector</span>
<span class="sd">        hidden_size : int</span>
<span class="sd">            The number of features in the hidden state</span>

<span class="sd">        """</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">RNNRegressionModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="n">num_layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">RNN</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">h0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">out</span><span class="p">,</span> <span class="n">hn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">h0</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>


<span class="k">class</span> <span class="nc">GRURegressionModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""GRU network with one recurrent layer"""</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        GRU network</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        input_size : int</span>
<span class="sd">            The number of expected features in the input vector</span>
<span class="sd">        hidden_size : int</span>
<span class="sd">            The number of features in the hidden state</span>

<span class="sd">        """</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GRURegressionModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="n">num_layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gru</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">h0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">out</span><span class="p">,</span> <span class="n">hn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gru</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">h0</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>
</pre></div>
</div>
</div>
</section>
<section id="Training">
<h3 id="Training">Training<a class="headerlink" href="#Training" title="Permalink to this heading">¶</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[57]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ModelTrainer</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""A class that provides training and validation infrastructure for the model and keeps track of training and validation metrics."""</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">clip_gradients</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Initialization.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model : nn.Module</span>
<span class="sd">            a model</span>
<span class="sd">        lr : float</span>
<span class="sd">            learning rate for one training step</span>

<span class="sd">        """</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">=</span> <span class="n">lr</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clip_gradients</span> <span class="o">=</span> <span class="n">clip_gradients</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">train_loss</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_loss</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_loss</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span> <span class="nf">_train_epoch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loader</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="n">epoch_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">batch_losses</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">X_batch</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">loader</span><span class="p">):</span>
            <span class="n">X_batch</span><span class="p">,</span> <span class="n">y_batch</span> <span class="o">=</span> <span class="n">X_batch</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y_batch</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">y_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">X_batch</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_batch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip_gradients</span><span class="p">:</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">max_norm</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">norm_type</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="n">epoch_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">batch_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

        <span class="k">return</span> <span class="n">epoch_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">loader</span><span class="p">),</span> <span class="n">batch_losses</span>

    <span class="k">def</span> <span class="nf">_eval_epoch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loader</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">val_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">targets</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">X_batch</span><span class="p">,</span> <span class="n">y_batch</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">:</span>
                <span class="n">X_batch</span><span class="p">,</span> <span class="n">y_batch</span> <span class="o">=</span> <span class="n">X_batch</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y_batch</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                <span class="n">y_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">X_batch</span><span class="p">)</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_batch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
                <span class="n">val_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="n">predictions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_pred</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
                <span class="n">targets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_batch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>

        <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
        <span class="n">targets</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">val_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">loader</span><span class="p">),</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span>

    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">n_epochs</span><span class="p">,</span> <span class="n">print_every</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Train the model</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        train_loader :</span>
<span class="sd">            a dataloader with training data</span>
<span class="sd">        val_loader :</span>
<span class="sd">            a dataloader with training data</span>
<span class="sd">        n_epochs :</span>
<span class="sd">            number of epochs to train for</span>
<span class="sd">        """</span>
        <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">):</span>
            <span class="n">train_loss</span><span class="p">,</span> <span class="n">train_loss_batches</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_epoch</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>
            <span class="n">val_loss</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_eval_epoch</span><span class="p">(</span><span class="n">test_loader</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">batch_loss</span> <span class="o">+=</span> <span class="n">train_loss_batches</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_loss</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">val_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_loss</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">e</span> <span class="o">%</span> <span class="n">print_every</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Epoch </span><span class="si">{</span><span class="n">e</span><span class="o">+</span><span class="mi">0</span><span class="si">:</span><span class="s2">03</span><span class="si">}</span><span class="s2"> | train_loss: </span><span class="si">{</span><span class="n">train_loss</span><span class="si">:</span><span class="s2">.5f</span><span class="si">}</span><span class="s2"> | val_loss: </span><span class="si">{</span><span class="n">val_loss</span><span class="si">:</span><span class="s2">.5f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">validate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Validate the model</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        val_loader :</span>
<span class="sd">            a dataloader with training data</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Tuple[list, list, list]</span>
<span class="sd">            Loss, y_predicted, y_target for each datapoint in val_loader.</span>
<span class="sd">        """</span>
        <span class="n">loss</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">y_targ</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_eval_epoch</span><span class="p">(</span><span class="n">val_loader</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">y_targ</span>
</pre></div>
</div>
</div>
<p>Now we define the models and train them for 50 epochs. The hidden state has the same dimension for both models.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[58]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_rnn</span> <span class="o">=</span> <span class="n">ModelTrainer</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">RNNRegressionModel</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="mi">32</span><span class="p">),</span>
    <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[59]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_rnn</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="mi">51</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Epoch 000 | train_loss: 1.00060 | val_loss: 0.93796
Epoch 010 | train_loss: 0.63237 | val_loss: 0.56349
Epoch 020 | train_loss: 0.54434 | val_loss: 0.49586
Epoch 030 | train_loss: 0.51031 | val_loss: 0.47032
Epoch 040 | train_loss: 0.47616 | val_loss: 0.44936
Epoch 050 | train_loss: 0.46097 | val_loss: 0.49712
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[60]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_gru</span> <span class="o">=</span> <span class="n">ModelTrainer</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">GRURegressionModel</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="mi">32</span><span class="p">),</span>
    <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[61]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_gru</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="mi">51</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Epoch 000 | train_loss: 0.73387 | val_loss: 0.53829
Epoch 010 | train_loss: 0.43030 | val_loss: 0.40386
Epoch 020 | train_loss: 0.37359 | val_loss: 0.36704
Epoch 030 | train_loss: 0.33639 | val_loss: 0.34342
Epoch 040 | train_loss: 0.31038 | val_loss: 0.32925
Epoch 050 | train_loss: 0.29032 | val_loss: 0.31914
</pre></div></div>
</div>
</section>
<section id="Evaluation">
<h3 id="Evaluation">Evaluation<a class="headerlink" href="#Evaluation" title="Permalink to this heading">¶</a></h3>
<p>First, we compare our models’ performance during training. We have plotted the losses on the training and validation sets on each epoch. As we can see, the GRU model trains faster and has better overall performance compared to the Vanilla RNN.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[62]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model_rnn</span><span class="o">.</span><span class="n">train_loss</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">"RNN train"</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model_rnn</span><span class="o">.</span><span class="n">val_loss</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">"RNN val"</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model_gru</span><span class="o">.</span><span class="n">train_loss</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">"GRU train"</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model_gru</span><span class="o">.</span><span class="n">val_loss</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">"GRU val"</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">"epoch"</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">"MSE"</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/talktorials_T034_recurrent_neural_networks_45_0.png" src="../_images/talktorials_T034_recurrent_neural_networks_45_0.png"/>
</div>
</div>
<p>To further evaluate the performance of the models, we calculate the loss on the testing set and visually compare the predictions to the ground truth values. As we can see from the plot, Vanilla RNN tends to produce more skewed predictions compared to the GRU model.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[63]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">f</span><span class="p">,</span> <span class="n">axarr</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">constrained_layout</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">f</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">"Ground truth vs predicted values"</span><span class="p">)</span>

<span class="n">loss</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">y_targ</span> <span class="o">=</span> <span class="n">model_rnn</span><span class="o">.</span><span class="n">validate</span><span class="p">(</span><span class="n">test_loader</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"RNN test loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">axarr</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_targ</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">axarr</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">y_targ</span><span class="p">,</span> <span class="n">y_targ</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">"r"</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">axarr</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"RNN"</span><span class="p">)</span>

<span class="n">loss</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">y_targ</span> <span class="o">=</span> <span class="n">model_gru</span><span class="o">.</span><span class="n">validate</span><span class="p">(</span><span class="n">test_loader</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"GRU test loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">axarr</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_targ</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">axarr</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">y_targ</span><span class="p">,</span> <span class="n">y_targ</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">"r"</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">axarr</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"GRU"</span><span class="p">)</span>

<span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="n">axarr</span><span class="p">:</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">"y_pred"</span><span class="p">)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">"y_true"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
RNN test loss: 0.497
GRU test loss: 0.319
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/talktorials_T034_recurrent_neural_networks_47_1.png" src="../_images/talktorials_T034_recurrent_neural_networks_47_1.png"/>
</div>
</div>
</section>
</section>
<section id="Discussion">
<h2 id="Discussion">Discussion<a class="headerlink" href="#Discussion" title="Permalink to this heading">¶</a></h2>
<p>Natural language processing-based models proved to be a powerful tool for a wide range of molecular tasks. In this talktorial we introduced the basics of Recurrent Neural Network architectures and demonstrated their application to the regression task on the QM9 dataset. We have learned how to pre-process SMILES strings, build a model using PyTorch, and train the model to predict the dipole moment of the molecule.</p>
</section>
<section id="Quiz">
<h2 id="Quiz">Quiz<a class="headerlink" href="#Quiz" title="Permalink to this heading">¶</a></h2>
<ol class="arabic simple">
<li><p>What problems do the recurrent neural networks experience during training?</p></li>
<li><p>In this talktorial we used a regex-based tokenizer. What other tokenization approaches could be used?</p></li>
<li><p>Why Gated recurrent unit architecture is better for capturing long-term relations?</p></li>
</ol>
<script type="application/vnd.jupyter.widget-state+json">
{"state": {}, "version_major": 2, "version_minor": 0}
</script></section>
</section>


          </article>
        </div>
      </div>
    </main>
  </div>
  <footer class="md-footer">
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
          
            <a href="T033_molecular_representations.html" title="T033 · Molecular representations"
               class="md-flex md-footer-nav__link md-footer-nav__link--prev"
               rel="prev">
              <div class="md-flex__cell md-flex__cell--shrink">
                <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
              </div>
              <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
                <span class="md-flex__ellipsis">
                  <span
                      class="md-footer-nav__direction"> Previous </span> T033 · Molecular representations </span>
              </div>
            </a>
          
          
            <a href="T035_graph_neural_networks.html" title="T035 · GNN-based molecular property prediction"
               class="md-flex md-footer-nav__link md-footer-nav__link--next"
               rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title"><span
                class="md-flex__ellipsis"> <span
                class="md-footer-nav__direction"> Next </span> T035 · GNN-based molecular property prediction </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink"><i
                class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          
        </a>
        
      </nav>
    </div>
    <div class="md-footer-meta md-typeset">
      <div class="md-footer-meta__inner md-grid">
        <div class="md-footer-copyright">
          <div class="md-footer-copyright__highlight">
              &#169; Copyright 2018-2023, Volkamer Lab. Project structure based on the Computational Molecular Science Python Cookiecutter version 1.1.
              
          </div>
            Created using
            <a href="http://www.sphinx-doc.org/">Sphinx</a> 7.0.1.
             and
            <a href="https://github.com/bashtage/sphinx-material/">Material for
              Sphinx</a>
        </div>
      </div>
    </div>
  </footer>
  <script src="../_static/javascripts/application.js"></script>
  <script>app.initialize({version: "1.0.4", url: {base: ".."}})</script>
  </body>
</html>